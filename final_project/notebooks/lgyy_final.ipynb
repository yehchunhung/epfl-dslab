{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Begin With...\n",
    "\n",
    "### Name your spark application as `GASPAR_final` or `GROUP_NAME_final`.\n",
    "\n",
    "<div class='alert alert-info'><b>Any application without a proper name would be promptly killed.</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'executorMemory': '40g', 'driverMemory': '16g', 'driverCores': 16, 'executorCores': 8, 'conf': {'spark.app.name': 'lgyy_final'}, 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>9463</td><td>application_1589299642358_4053</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_4053/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster070.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_4053_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9470</td><td>application_1589299642358_4061</td><td>pyspark</td><td>dead</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/cluster/app/application_1589299642358_4061\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster054.iccluster.epfl.ch:8188/applicationhistory/logs/iccluster070.iccluster.epfl.ch:45454/container_e06_1589299642358_4061_01_000001/container_e06_1589299642358_4061_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9472</td><td>application_1589299642358_4064</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_4064/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster069.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_4064_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9473</td><td>application_1589299642358_4065</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_4065/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster065.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_4065_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9475</td><td>application_1589299642358_4067</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_4067/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster072.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_4067_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9476</td><td>application_1589299642358_4068</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_4068/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster071.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_4068_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9479</td><td>application_1589299642358_4071</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_4071/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster072.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_4071_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9480</td><td>application_1589299642358_4072</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_4072/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster068.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_4072_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9481</td><td>application_1589299642358_4073</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_4073/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster071.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_4073_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9484</td><td>application_1589299642358_4076</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_4076/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster071.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_4076_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9485</td><td>application_1589299642358_4077</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_4077/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster068.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_4077_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9486</td><td>application_1589299642358_4078</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_4078/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster072.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_4078_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9488</td><td>application_1589299642358_4081</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_4081/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster066.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_4081_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9489</td><td>application_1589299642358_4082</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_4082/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster066.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_4082_01_000002/ebouille\">Link</a></td><td></td></tr><tr><td>9490</td><td>application_1589299642358_4083</td><td>pyspark</td><td>dead</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/cluster/app/application_1589299642358_4083\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster054.iccluster.epfl.ch:8188/applicationhistory/logs/iccluster071.iccluster.epfl.ch:45454/container_e06_1589299642358_4083_01_000001/container_e06_1589299642358_4083_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9491</td><td>application_1589299642358_4084</td><td>pyspark</td><td>dead</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/cluster/app/application_1589299642358_4084\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster054.iccluster.epfl.ch:8188/applicationhistory/logs/iccluster069.iccluster.epfl.ch:45454/container_e06_1589299642358_4084_01_000001/container_e06_1589299642358_4084_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9493</td><td>application_1589299642358_4086</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_4086/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster072.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_4086_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9494</td><td>application_1589299642358_4087</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_4087/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster065.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_4087_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9495</td><td>application_1589299642358_4088</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_4088/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster070.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_4088_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9497</td><td>application_1589299642358_4090</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_4090/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster070.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_4090_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9498</td><td>application_1589299642358_4091</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_4091/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster068.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_4091_01_000001/ebouille\">Link</a></td><td></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure\n",
    "{\n",
    "    \"executorMemory\": \"40g\",\n",
    "    \"driverMemory\":\"16g\",\n",
    "    \"driverCores\":16,\n",
    "    \"executorCores\": 8,\n",
    "    \"conf\": {\n",
    "        \"spark.app.name\": \"lgyy_final\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>9499</td><td>application_1589299642358_4092</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_4092/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster071.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_4092_01_000001/ebouille\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import pyspark.sql.functions as functions\n",
    "from pyspark.sql.types import BooleanType, FloatType, IntegerType, ArrayType, LongType\n",
    "from pyspark.sql.window import Window\n",
    "import datetime\n",
    "import networkx as nx\n",
    "import math\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import functools\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the [SBB actual data](https://opentransportdata.swiss/en/dataset/istdaten) in ORC format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sbb = spark.read.orc('/data/sbb/orc/istdaten')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- betriebstag: string (nullable = true)\n",
      " |-- fahrt_bezeichner: string (nullable = true)\n",
      " |-- betreiber_id: string (nullable = true)\n",
      " |-- betreiber_abk: string (nullable = true)\n",
      " |-- betreiber_name: string (nullable = true)\n",
      " |-- produkt_id: string (nullable = true)\n",
      " |-- linien_id: string (nullable = true)\n",
      " |-- linien_text: string (nullable = true)\n",
      " |-- umlauf_id: string (nullable = true)\n",
      " |-- verkehrsmittel_text: string (nullable = true)\n",
      " |-- zusatzfahrt_tf: string (nullable = true)\n",
      " |-- faellt_aus_tf: string (nullable = true)\n",
      " |-- bpuic: string (nullable = true)\n",
      " |-- haltestellen_name: string (nullable = true)\n",
      " |-- ankunftszeit: string (nullable = true)\n",
      " |-- an_prognose: string (nullable = true)\n",
      " |-- an_prognose_status: string (nullable = true)\n",
      " |-- abfahrtszeit: string (nullable = true)\n",
      " |-- ab_prognose: string (nullable = true)\n",
      " |-- ab_prognose_status: string (nullable = true)\n",
      " |-- durchfahrt_tf: string (nullable = true)"
     ]
    }
   ],
   "source": [
    "sbb.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of project\n",
    "\n",
    "**The link of our video:** https://www.youtube.com/watch?v=9uN3iFn2rzU&feature=youtu.be\n",
    "\n",
    "### 1, Team members: Lei Yan, Yueran Liang, Saibo Geng, Chun-Hung Yeh\n",
    "\n",
    "### 2. Work distributions:\n",
    "\n",
    "Part I Data preprocessing:                                         Yeh & Yan\n",
    "\n",
    "Part II Obtaining historical delay data:                           Yan\n",
    "\n",
    "Part III Modelling transport infrastructure:                       Liang\n",
    "\n",
    "Part IV Basic Route Planning Algorithm:                            Geng & Liang\n",
    "\n",
    "Part V Evaluate the route uncertainty based on historical delay:   Yan & Geng\n",
    "\n",
    "Code review:                                                       Yeh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Part I] Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "In this part, we do the following data cleaning operations:\n",
    "\n",
    "- timetable:\n",
    "    - Construct the timetable dataset by joining the stops, stop_times, calendar, trips, routes tables\n",
    "    - Keep only rows with stops inside Zurich neighborhood (< 15km from Zurich HB)\n",
    "    - Only keep services that run at least from Mon to Fri\n",
    "    - Only keep the schedule in the reasonable hours (7:00 to 20:00)\n",
    "    \n",
    "- sbb:\n",
    "    - Keep only rows with stops inside Zurich neighborhood (< 15km from Zurich HB)\n",
    "    - Reformat ill-formatted stop names to match it with those in timetable "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning timetable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# helper functions\n",
    "\n",
    "# Calculate distance using (long, lat)\n",
    "def hav(x):\n",
    "    \"\"\"haversine function \"\"\"\n",
    "    return (1 - math.cos(x)) / 2\n",
    "\n",
    "def distance(long1, lat1, long2, lat2):\n",
    "    \"\"\"\n",
    "    Compute the distance in kms between two locations given their coordinates (longitude, latitude).\n",
    "    \"\"\"\n",
    "    # convert decimal degrees to radians \n",
    "    long1, long2, lat1, lat2 = [math.radians(x) for x in [long1, long2, lat1, lat2]]\n",
    "    \n",
    "    # earth radius\n",
    "    r = 6371 \n",
    "    \n",
    "    # haversine formula\n",
    "    return 2*r*math.asin(math.sqrt(hav(lat2 - lat1) + math.cos(lat1) * math.cos(lat2) * hav(long2-long1)))\n",
    "\n",
    "# coordinate of Zurich HB\n",
    "lat_zurich = 47.378177\n",
    "lon_zurich = 8.540192\n",
    "\n",
    "# Calulate distance to Zurich HB\n",
    "def get_distance(lon, lat):\n",
    "    return distance(lon, lat, lon_zurich, lat_zurich)\n",
    "\n",
    "distance_getter = functions.udf(lambda x,y: get_distance(x,y), FloatType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### load and clean stops\n",
    "stops = spark.read.orc(\"hdfs:///data/sbb/timetables/orc/stops\")\n",
    "\n",
    "# keep only the stops that are located < 15km from Zurich HB\n",
    "stops = stops.withColumn('distance', distance_getter('stop_lon', 'stop_lat'))\n",
    "stops = stops.where(stops.distance < 15)\n",
    "\n",
    "\n",
    "### Construct station table\n",
    "# Construct a table of stations(stations can have single or multiple stops/platforms),\n",
    "# will be used to construct the \"walking distance between stations\" network\n",
    "# Get list of stops of each station\n",
    "stations = stops.groupBy('stop_name').agg(functions.collect_list('stop_id').alias('stops'),\n",
    "                                          functions.mean('stop_lat').alias('station_lat'),\n",
    "                                          functions.mean('stop_lon').alias('station_lon'))\n",
    "stations = stations.withColumnRenamed('stop_name', 'station_name')\n",
    "\n",
    "### For fellow developers:\n",
    "# The stations table can be then used to construct the \"walking distance between stations\" network\n",
    "# In route planning algorithm the table can be indexed by \"station_name\" (same as \"stop_name\" in stops table)\n",
    "# and the list of all stops of the same station can be looked up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+------------------+----------------+\n",
      "|     station_name|               stops|       station_lat|     station_lon|\n",
      "+-----------------+--------------------+------------------+----------------+\n",
      "|Zufikon Belvédère|[8502268, 8502268...|47.357611660093596|8.35923694492646|\n",
      "+-----------------+--------------------+------------------+----------------+"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "stations.where(stations.station_name == 'Zufikon Belvédère').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Create and clean timetable\n",
    "stop_times = spark.read.orc(\"hdfs:///data/sbb/timetables/orc/stop_times\")\n",
    "calendar = spark.read.orc(\"hdfs:///data/sbb/timetables/orc/calendar\")\n",
    "trips = spark.read.orc(\"hdfs:///data/sbb/timetables/orc/trips\")\n",
    "routes = spark.read.orc(\"hdfs:///data/sbb/timetables/orc/routes\")\n",
    "\n",
    "# Only keep services that run at least from Mon to Fri\n",
    "calendar = calendar.where(calendar.monday & calendar.tuesday & calendar.wednesday\n",
    "                                          & calendar.thursday & calendar.friday)\n",
    "\n",
    "# merge to a suitable timetable,\n",
    "# used to construct the \"zurich transport\" network\n",
    "timetable = stop_times.join(stops, on = ['stop_id'], how = 'inner')\\\n",
    "                      .join(trips, on = ['trip_id'], how = 'inner')\\\n",
    "                      .join(calendar, on = ['service_id'], how = 'inner')\\\n",
    "                      .join(routes, on = ['route_id'], how = 'inner')\n",
    "\n",
    "# Only keep the schedule in the reasonable hours (7:00 to 20:00)\n",
    "timetable = timetable.where(((functions.hour(timetable.departure_time) >= 7) & (functions.hour(timetable.departure_time) <= 19)) |\n",
    "                ((functions.hour(timetable.arrival_time) >= 7) & (functions.hour(timetable.arrival_time) <= 19)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning istdaten(sbb) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### rename attributes from German to English\n",
    "fields = {\n",
    "    'betriebstag':'date',\n",
    "    'fahrt_bezeichner':'trip_id',\n",
    "    'produkt_id':'transport_type',\n",
    "    'linien_id':'train_id',\n",
    "    'linien_text':'line',\n",
    "    'verkehrsmittel_text':'train_type',\n",
    "    'zusatzfahrt_tf':'additional_trip',\n",
    "    'faellt_aus_tf':'trip_failed',\n",
    "    'haltestellen_name':'stop_name',\n",
    "    'bpuic':'stop_id',\n",
    "    'ankunftszeit':'schedule_arrival',\n",
    "    'an_prognose':'real_arrival',\n",
    "    'an_prognose_status':'arr_forecast_status',\n",
    "    'abfahrtszeit':'schedule_dep',\n",
    "    'ab_prognose':'real_dep',\n",
    "    'ab_prognose_status':'dep_forecast_status',\n",
    "    'durchfahrt_tf':'no_stop_here'\n",
    "}\n",
    "\n",
    "df = sbb.selectExpr([k + ' as ' + fields[k] for k in fields])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Clean up table sbb\n",
    "# keep only the rows with stops near Zurich:\n",
    "#     Join table sbb with table stops to filter out sbb data outside the zurich region (>15 km from Zurich HB)\n",
    "#     Both table have column \"stop_name\"\n",
    "#     In sbb, \"stop_name\" is not clean, it has duplicates like \"Zurich, Balgrist\" and \"Zurich Balgrist\"\n",
    "#     In stops, it is clean. Thus we remove the dirty \"stop_name\" from sbb before join\n",
    "\n",
    "# Construct a table containing stop ids in the format of the stop ids in sbb\n",
    "def get_sbb_stop_id(id):\n",
    "    return id.split(':')[0]\n",
    "\n",
    "sbb_stop_id_getter = functions.udf(lambda x: get_sbb_stop_id(x))\n",
    "temp_stops = stops.withColumn('stop_id', sbb_stop_id_getter('stop_id'))\n",
    "temp_stops = temp_stops.groupBy('stop_id', 'stop_name').count().withColumnRenamed('count', 'num')\n",
    "temp_stops = temp_stops.drop('num')\n",
    "\n",
    "df_no_name = df.drop('stop_name')\n",
    "df1 = df_no_name.join(temp_stops, 'stop_id', 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#df1.write.format(\"orc\").save(path=\"hdfs:///user/lyan/temp_data/joined_sbb_stops.orc\", mode=\"overwrite\")\n",
    "\n",
    "### This process takes a couple of minutes, use the following line to read the results directly from HDFS\n",
    "sbb = spark.read.orc(\"hdfs:///user/lyan/temp_data/joined_sbb_stops.orc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Part II] Get delay info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "We assume arrival delays occured at the same stop, of the same transport line, at the same arrival time follow the same\n",
    "probability distribution. A \"transport line\" refers to a certain line of a certain type of transport of a certain transport agency.\n",
    "\n",
    "In this part, we retrieve the list of historical arrival delays for each {transport line, stop, arrival time} triple based on\n",
    "historical data from the sbb dataset. This information will be used to build the predictive model for predicting arrival delays of a stop of a trip (i.e, a row in timetable).\n",
    "\n",
    "#### Step 1: Obtaining the triple\n",
    "\n",
    "\"transport line\" is not directly available in both of the sbb and timetable datasets.\n",
    "\n",
    "We observed that in the sbb dataset, the column \"train_id\" has the following format:\n",
    "- \"85:agency_id:line_number\" for bus/tram, where agency_id and line_number are the columns agency_id, route_short_name in the timetable, respectively.\n",
    "- \"line_number\" for trains, where line_number is the column trip_short_name in the timetable.\n",
    "\n",
    "This \"train_id\" column can uniquely identify transport lines except for trains. We observed that for trains \"train_id\" is only unqiue for one type of train, thus we need to combine it with type of trains (corresponds to \"route_desc\" in timetable and \"train_type\" in sbb) to make it unique.\n",
    "\n",
    "Based on the discussion above, we construct a \"lineID\" column (i.e., \"transport line\") for both of the tables in the following manner:\n",
    "\n",
    "- sbb:\n",
    "    - \"train_id\" for buses and trams\n",
    "    - \"train_type:train_id\" for trains\n",
    "\n",
    "- timetable:\n",
    "    - \"85:agency_id:route_short_name\" for buses and trams\n",
    "    - \"route_desc:trip_short_name\" for trains\n",
    "    \n",
    "\"stop\" and \"arrival_time\" is directly available in both datasets.\n",
    "\n",
    "#### Step 2: Obtaining historical delay lists\n",
    "\n",
    "In this step we join the sbb and timetable datasets on the triple to get a list of historical delay data for each row in the timetable (if available).\n",
    "\n",
    "We found that the triple is not unique within timetable. There are some corner cases leading to this:\n",
    "- There are duplicate trips in the timetable, their rows only differ in the trip_id, all other columns are identical. After checking the corresponding records in the sbb table, we found that these trips are identical in all aspects, only that they run on different dates.\n",
    "- In some cases, two trips belonging to the same transport line running in opposite direction can stop at the same station at the same time.\n",
    "\n",
    "This means we cannot directly join the sbb and timetable on the triple. But this can be easily worked-around. We first extract a table containing all the unique triple values found in timetable. Then we join the sbb dataset with this triple table, this way we get the historical delays for each of the triple. In the last step, we join the timetable to the triple table, such that we get the list of historical delays for each row of the timetable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Code] Construct the triple in timetable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Print transport types in both tables\n",
    "#timetable.groupBy('route_desc').count().show()\n",
    "#sbb.groupBy('transport_type', 'train_type').count().orderBy('transport_type').show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### convert transport type in timetable to the format used in sbb \n",
    "def map_timetable_transport_type(orig):\n",
    "    map = {\n",
    "        \"TGV\": \"TGV\",\n",
    "        \"Eurocity\": \"EC\",\n",
    "        \"RegioExpress\": \"RE\",\n",
    "        \"S-Bahn\": \"S\",\n",
    "        \"Tram\": \"Tram\",\n",
    "        \"ICE\": \"ICE\",\n",
    "        \"Bus\": \"Bus\",\n",
    "        \"Intercity\": \"IC\",\n",
    "        \"InterRegio\": \"IR\"\n",
    "    }\n",
    "    return map.get(orig)\n",
    "transport_type_mapper = functions.udf(lambda x: map_timetable_transport_type(x))\n",
    "timetable = timetable.withColumn('route_desc', transport_type_mapper('route_desc'))\n",
    "\n",
    "# remove null transport type (i.e., those do not have a match in sbb)\n",
    "timetable = timetable.where(timetable.route_desc.isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### TEST\n",
    "#timetable.groupBy('route_desc').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Construct the lineID for timetable\n",
    "def timetable_get_uid(route_desc, agency_id, trip_short_name, route_short_name):\n",
    "    # 85 is found in the train_id (linien_id) column of sbb\n",
    "    # whenever the transport is tram or bus\n",
    "    if (route_desc == 'Bus'):\n",
    "        lineID = u\"85:{}:{}\".format(agency_id, route_short_name)\n",
    "    elif (route_desc == 'Tram'):\n",
    "        # The tram line ID in sbb always has 3 digits\n",
    "        # format the tram line ID here to match that representation\n",
    "        num_zero_prefix = 3 - len(route_short_name)\n",
    "        zero_prefix = '0' * num_zero_prefix\n",
    "        route_short_name = zero_prefix + route_short_name\n",
    "        lineID = u\"85:{}:{}\".format(agency_id, route_short_name)\n",
    "    else:\n",
    "        lineID = u\"{}:{}\".format(route_desc, trip_short_name)\n",
    "    return lineID\n",
    "timetable_uid_getter = functions.udf(lambda a,b,c,d: timetable_get_uid(a, b, c, d))\n",
    "\n",
    "timetable = timetable.withColumn('lineID', timetable_uid_getter('route_desc', 'agency_id', 'trip_short_name', 'route_short_name'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Select relevant columns\n",
    "timetable = timetable.select('trip_id', 'stop_id', 'arrival_time', 'departure_time', 'stop_sequence', 'stop_name',\n",
    "                             'stop_lat', 'stop_lon', 'location_type', 'parent_station', 'trip_headsign', 'trip_short_name',\n",
    "                             'route_short_name', 'direction_id', 'agency_id', 'route_desc', 'lineID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#timetable.write.format(\"orc\").save(path=\"hdfs:///user/lyan/temp_data/timetable_temp.orc\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Use pre-saved data\n",
    "timetable = spark.read.orc(\"hdfs:///user/lyan/temp_data/timetable_temp.orc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Confirming for starting stop (depart = arrival)\n",
    "#timetable.where(timetable.stop_sequence == 1).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#timetable.where(timetable.stop_sequence == 1).where(timetable.departure_time == timetable.arrival_time).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Code] Construct the triple table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Construct the triple table\n",
    "\n",
    "timetable_uid = timetable.groupBy('lineID', 'stop_name', 'arrival_time').count()\n",
    "timetable_uid = timetable_uid.drop('count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Code] Construct the triple in sbb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Further cleaning of sbb data\n",
    "\n",
    "# discard rows belonging to cancelled trips\n",
    "# discard the rows when there is no stop here\n",
    "sbb = sbb.where((sbb.trip_failed == 'false') & (sbb.no_stop_here == 'false'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Select relevant columns\n",
    "sbb = sbb.select('trip_id', 'train_type', 'transport_type', 'train_id', 'stop_name',\n",
    "                 'schedule_dep', 'schedule_arrival', 'real_arrival', 'real_dep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###Test\n",
    "#sbb.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Temp\n",
    "# sbb.groupBy('transport_type', 'train_type').count().orderBy('transport_type').show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate arrival delay\n",
    "# Remove negative or \"null\" arrival delay, except for starting station\n",
    "sbb = sbb.withColumn('arr_delay',  functions.unix_timestamp('real_arrival', 'dd.MM.yyyy HH:mm:ss')\n",
    "                                 - functions.unix_timestamp('schedule_arrival', 'dd.MM.yyyy HH:mm'))\n",
    "sbb = sbb.where((sbb.arr_delay >= 0) | (sbb.real_arrival == ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Construct lineID field for sbb\n",
    "\n",
    "def sbb_get_uid(transport_type, train_type, train_id):\n",
    "    # Use \"train_id\" as lineID for Bus or Tram\n",
    "    if ((transport_type == 'Bus') | (transport_type == 'Tram')):\n",
    "        lineID = train_id\n",
    "    # train_id is only unique for one train_type\n",
    "    # Use train_type + train_id for trains\n",
    "    elif (transport_type == 'Zug'):   \n",
    "        lineID = u\"{}:{}\".format(train_type, train_id)\n",
    "    # No lineID for rows without clear transport_type\n",
    "    else:\n",
    "        lineID = None\n",
    "    return lineID\n",
    "sbb_uid_getter = functions.udf(lambda a,b,c: sbb_get_uid(a, b, c))\n",
    "\n",
    "sbb = sbb.withColumn('lineID', sbb_uid_getter('transport_type', 'train_type', 'train_id'))\n",
    "\n",
    "sbb = sbb.where(sbb.lineID.isNotNull())\n",
    "\n",
    "sbb = sbb.drop('transport_type', 'train_type', 'train_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#sbb.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Reformat & rename \"schedule_arrival\" column to match the \"arrival_time\" column in timetable\n",
    "\n",
    "def ts_convert(arr, depart):\n",
    "    # Check if starting station\n",
    "    if arr == '':\n",
    "        arr = depart\n",
    "    return arr.split(' ')[-1] + ':00'\n",
    "ts_converter = functions.udf(lambda x,y: ts_convert(x,y))\n",
    "\n",
    "sbb = sbb.withColumn('arrival_time', ts_converter('schedule_arrival', 'schedule_dep'))\n",
    "\n",
    "sbb = sbb.drop('trip_id', 'schedule_dep', 'schedule_arrival', 'real_arrival', 'real_dep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#sbb.write.format(\"orc\").save(path=\"hdfs:///user/lyan/temp_data/sbb_ready_to_join.orc\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Code] Obtain historical delay lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load pre-saved data\n",
    "sbb = spark.read.orc(\"hdfs:///user/lyan/temp_data/sbb_ready_to_join.orc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Join sbb with triple table\n",
    "joined_sbb = sbb.join(timetable_uid, on = ['lineID', 'stop_name', 'arrival_time'], how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#joined_sbb.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Get historical delay lists of each triple\n",
    "delay_list = joined_sbb.groupBy('lineID', 'stop_name', 'arrival_time').agg(functions.collect_list('arr_delay').alias('delays'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#delay_list.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Append corresponding historical delay list to each row of timetable\n",
    "timetable_w_delays = timetable.join(delay_list, on = ['lineID', 'stop_name', 'arrival_time'], how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#delay_list.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#timetable_w_delays.write.format(\"orc\").save(path=\"hdfs:///user/lyan/temp_data/timetable_w_delay.orc\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Part III] Model the public transport infrastructure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we need to build three network as follows to serve the algorithm in partIV:\n",
    "1. Network according to trip_id, stop_id, stop_sequence; Because there are some stops which are skipped in some trips even they are in the same routes.\n",
    "2. Network for transfer among stops in the same station\n",
    "3. Walking Network. This network is built according to pairwise distance of stops which are less than 500m. Some stops which have been included in the same station transfer network are exclude of this network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network based on trip id, stop id, stop sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#load pre-saved data\n",
    "timetable_w_delays = spark.read.orc(\"hdfs:///user/lyan/temp_data/timetable_w_delay.orc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# change to date time\n",
    "new_timetable = timetable_w_delays.withColumn('arrival_time', functions.from_unixtime(functions.unix_timestamp('arrival_time', 'HH:mm:ss'), 'HH:mm:ss'))\n",
    "new_timetable = new_timetable.withColumn('departure_time', functions.from_unixtime(functions.unix_timestamp('departure_time', 'HH:mm:ss'), 'HH:mm:ss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# select related columns construct network\n",
    "trip_info = new_timetable.select('trip_id','stop_id','stop_name','stop_lat','stop_lon','arrival_time', 'departure_time','stop_sequence')\n",
    "# group all stops by trip_id\n",
    "info_df = trip_info.groupBy('trip_id').agg(collect_list(array(\"stop_id\", \"stop_sequence\"))).withColumnRenamed(\"collect_list(array(stop_id, stop_sequence))\", \"stops\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sort_stops_by_arr(x):\n",
    "    \"\"\"\n",
    "    sort (stop,sequence) array according to sequence in the trip\n",
    "    \"\"\"\n",
    "    xx = map(lambda d: [d[0],int(d[1])],x)\n",
    "    return sorted(xx,key=lambda s:s[1])\n",
    "sort_stops_udf = udf(sort_stops_by_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|trip_id                 |sorted_stops                                                                                                                                                                                                                                                                          |\n",
      "+------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|104.TA.26-733-j19-1.2.R |[[8573205:0:D, 1], [8580301, 2], [8588553, 3], [8573211, 4], [8590699, 5], [8587420, 6], [8580434, 7], [8576153, 8], [8580433, 9]]                                                                                                                                                    |\n",
      "|111.TA.79-736-j19-1.5.H |[[8591031, 1], [8588553, 2], [8580301, 3], [8573205:0:L, 4], [8573213:0:C, 5], [8587799, 6], [8591032, 7], [8593523, 8]]                                                                                                                                                              |\n",
      "|1139.TA.26-156-j19-1.4.R|[[8573167, 1], [8590824, 2], [8590822, 3], [8590811, 4], [8590826, 5], [8595406, 6], [8590828, 7], [8590780, 8], [8590779, 9], [8590775, 10], [8590777, 11], [8590482, 12], [8590464, 13]]                                                                                            |\n",
      "|12.TA.26-162-j19-1.1.R  |[[8590679, 1], [8590476, 2], [8590473, 3], [8590678, 4], [8590670, 5], [8590675, 6], [8590680, 7], [8590690, 8], [8590689, 9], [8590673, 10]]                                                                                                                                         |\n",
      "|1388.TA.26-8-C-j19-1.8.R|[[8591233, 1], [8591199, 2], [8530813, 5], [8503059, 6], [8576193, 7], [8591105, 8], [8591093, 9], [8591299, 10], [8591384, 11], [8591064, 12], [8591184, 14], [8591052, 15], [8591169, 16], [8591177, 17], [8594239, 19], [8580522, 20], [8591135, 21], [8591178, 24]]               |\n",
      "|150.TA.26-142-j19-1.1.H |[[8573167, 1], [8590829, 2], [8590823, 3], [8590814, 4], [8590812, 5], [8590817, 6], [8590815, 7]]                                                                                                                                                                                    |\n",
      "|1513.TA.26-3-A-j19-1.8.R|[[8591233, 1], [8591199, 2], [8591202, 4], [8591239, 5], [8591287, 6], [8588078, 7], [8587348, 8], [8591367, 10], [8591381, 11], [8591079, 12], [8591218, 13], [8591259, 14], [8591448, 15], [8591038, 16], [8591236, 17], [8591203, 18], [8591363, 19], [8591126, 20], [8591036, 21]]|\n",
      "|180.TA.26-132-j19-1.2.H |[[8503855:0:D, 1], [8577912, 2], [8577867, 3]]                                                                                                                                                                                                                                        |\n",
      "|183.TA.26-142-j19-1.1.H |[[8573167, 1], [8590829, 2], [8590823, 3], [8590814, 4], [8590812, 5], [8590817, 6], [8590815, 7]]                                                                                                                                                                                    |\n",
      "|192.TA.26-132-j19-1.2.H |[[8503855:0:D, 1], [8577912, 2], [8577867, 3]]                                                                                                                                                                                                                                        |\n",
      "+------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 10 rows"
     ]
    }
   ],
   "source": [
    "# sort stop according to sequence for each trip\n",
    "trip = info_df.withColumn('sorted_stops',sort_stops_udf('stops')).select('trip_id','sorted_stops')\n",
    "trip.show(10,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trip_df = trip.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       dst  dst_sequence          src  src_sequence                  trip_id\n",
      "0  8580301             2  8573205:0:D             1  104.TA.26-733-j19-1.2.R\n",
      "1  8588553             3      8580301             2  104.TA.26-733-j19-1.2.R\n",
      "2  8573211             4      8588553             3  104.TA.26-733-j19-1.2.R\n",
      "3  8590699             5      8573211             4  104.TA.26-733-j19-1.2.R\n",
      "4  8587420             6      8590699             5  104.TA.26-733-j19-1.2.R"
     ]
    }
   ],
   "source": [
    "# constuct netowrk\n",
    "# because in one trip, some stops can be repeated more than once or be skipped\n",
    "# so we preserve the sequence NO. of them\n",
    "import re\n",
    "nw = {'trip_id':[],'src':[],'dst':[],'src_sequence':[],'dst_sequence':[]}\n",
    "for record in trip_df.values:\n",
    "    if ',' not in record[1]:\n",
    "        continue\n",
    "    tmp = re.sub(r\"^\\[{1}\", \"\", record[1])\n",
    "    tmp = re.sub(r\"\\]{1}$\", \"\", tmp)\n",
    "    tmp = re.sub(r\"], \", \"]-\", tmp)\n",
    "    stops = tmp.split('-')\n",
    "    stop_sequence = [s.lstrip('[').rstrip(']').split(',') for s in stops ]\n",
    "    for i in range(len(stop_sequence)):\n",
    "        if (i+1)==len(stop_sequence):\n",
    "            break\n",
    "        nw['src'].append(stop_sequence[i][0].strip().encode('ascii', 'ignore'))\n",
    "        nw['src_sequence'].append(int(stop_sequence[i][1]))\n",
    "        nw['dst'].append(stop_sequence[i+1][0].strip().encode('ascii', 'ignore'))\n",
    "        nw['dst_sequence'].append(int(stop_sequence[i+1][1]))\n",
    "        nw['trip_id'].append(record[0].strip().encode('ascii', 'ignore'))\n",
    "nw_df = pd.DataFrame(nw)\n",
    "nw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+-----------+------------+--------------------+\n",
      "|        dst|dst_sequence|        src|src_sequence|             trip_id|\n",
      "+-----------+------------+-----------+------------+--------------------+\n",
      "|    8580301|           2|8573205:0:D|           1|104.TA.26-733-j19...|\n",
      "|    8588553|           3|    8580301|           2|104.TA.26-733-j19...|\n",
      "|    8573211|           4|    8588553|           3|104.TA.26-733-j19...|\n",
      "|    8590699|           5|    8573211|           4|104.TA.26-733-j19...|\n",
      "|    8587420|           6|    8590699|           5|104.TA.26-733-j19...|\n",
      "|    8580434|           7|    8587420|           6|104.TA.26-733-j19...|\n",
      "|    8576153|           8|    8580434|           7|104.TA.26-733-j19...|\n",
      "|    8580433|           9|    8576153|           8|104.TA.26-733-j19...|\n",
      "|    8588553|           2|    8591031|           1|111.TA.79-736-j19...|\n",
      "|    8580301|           3|    8588553|           2|111.TA.79-736-j19...|\n",
      "|8573205:0:L|           4|    8580301|           3|111.TA.79-736-j19...|\n",
      "|8573213:0:C|           5|8573205:0:L|           4|111.TA.79-736-j19...|\n",
      "|    8587799|           6|8573213:0:C|           5|111.TA.79-736-j19...|\n",
      "|    8591032|           7|    8587799|           6|111.TA.79-736-j19...|\n",
      "|    8593523|           8|    8591032|           7|111.TA.79-736-j19...|\n",
      "|    8590824|           2|    8573167|           1|1139.TA.26-156-j1...|\n",
      "|    8590822|           3|    8590824|           2|1139.TA.26-156-j1...|\n",
      "|    8590811|           4|    8590822|           3|1139.TA.26-156-j1...|\n",
      "|    8590826|           5|    8590811|           4|1139.TA.26-156-j1...|\n",
      "|    8595406|           6|    8590826|           5|1139.TA.26-156-j1...|\n",
      "+-----------+------------+-----------+------------+--------------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "nw_spdf = spark.createDataFrame(nw_df)\n",
    "nw_spdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187032"
     ]
    }
   ],
   "source": [
    "nw_spdf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+-----------+-----------+--------+---------+\n",
      "|             trip_id| src_dep|        src|        dst| dst_arr|time_cost|\n",
      "+--------------------+--------+-----------+-----------+--------+---------+\n",
      "|104.TA.26-733-j19...|07:33:00|8573205:0:D|    8580301|07:33:00|        0|\n",
      "|104.TA.26-733-j19...|07:33:00|    8580301|    8588553|07:34:00|       60|\n",
      "|104.TA.26-733-j19...|07:34:00|    8588553|    8573211|07:36:00|      120|\n",
      "|104.TA.26-733-j19...|07:36:00|    8573211|    8590699|07:37:00|       60|\n",
      "|104.TA.26-733-j19...|07:37:00|    8590699|    8587420|07:40:00|      180|\n",
      "|104.TA.26-733-j19...|07:40:00|    8587420|    8580434|07:41:00|       60|\n",
      "|104.TA.26-733-j19...|07:41:00|    8580434|    8576153|07:42:00|       60|\n",
      "|104.TA.26-733-j19...|07:42:00|    8576153|    8580433|07:44:00|      120|\n",
      "|111.TA.79-736-j19...|18:39:00|    8591031|    8588553|18:41:00|      120|\n",
      "|111.TA.79-736-j19...|18:41:00|    8588553|    8580301|18:42:00|       60|\n",
      "|111.TA.79-736-j19...|18:42:00|    8580301|8573205:0:L|18:43:00|       60|\n",
      "|111.TA.79-736-j19...|18:44:00|8573205:0:L|8573213:0:C|18:45:00|       60|\n",
      "|111.TA.79-736-j19...|18:45:00|8573213:0:C|    8587799|18:46:00|       60|\n",
      "|111.TA.79-736-j19...|18:46:00|    8587799|    8591032|18:49:00|      180|\n",
      "|111.TA.79-736-j19...|18:49:00|    8591032|    8593523|18:51:00|      120|\n",
      "|1139.TA.26-156-j1...|11:57:00|    8573167|    8590824|11:58:00|       60|\n",
      "|1139.TA.26-156-j1...|11:58:00|    8590824|    8590822|11:59:00|       60|\n",
      "|1139.TA.26-156-j1...|11:59:00|    8590822|    8590811|12:00:00|       60|\n",
      "|1139.TA.26-156-j1...|12:00:00|    8590811|    8590826|12:01:00|       60|\n",
      "|1139.TA.26-156-j1...|12:01:00|    8590826|    8595406|12:02:00|       60|\n",
      "+--------------------+--------+-----------+-----------+--------+---------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "# join arrival time and departure time to network dataframe\n",
    "# again, as one stop may be repeated more than once, sequence NO. should also be considered to maintain their arrival & departure time\n",
    "tripmeta = trip_info.select(col(\"trip_id\").alias(\"meta_trip_id\"),'stop_id','arrival_time', 'departure_time','stop_sequence')\n",
    "tmp = nw_spdf.join(tripmeta, [nw_spdf.trip_id == tripmeta.meta_trip_id,nw_spdf.src == tripmeta.stop_id, nw_spdf.src_sequence == tripmeta.stop_sequence], how = 'inner')\\\n",
    "                    .select('trip_id',col('departure_time').alias('src_dep'),'src','dst','src_sequence','dst_sequence')\n",
    "edges_info = tmp.join(tripmeta, [tmp.trip_id == tripmeta.meta_trip_id,tmp.dst == tripmeta.stop_id,nw_spdf.dst_sequence == tripmeta.stop_sequence], how = 'inner')\\\n",
    "                    .select('trip_id','src_dep','src','dst',col('arrival_time').alias('dst_arr'),'dst_sequence','src_sequence')\n",
    "# change to datetime\n",
    "edges_info = edges_info.withColumn('unix_dep',unix_timestamp('src_dep', 'HH:mm:ss'))\n",
    "edges_info = edges_info.withColumn('unix_arr',unix_timestamp('dst_arr', 'HH:mm:ss'))\n",
    "# compute time cost for each edge\n",
    "edges_info = edges_info.withColumn('time_cost',(col('unix_arr') - col('unix_dep')))\n",
    "edges_info = edges_info.select('trip_id','src_dep','src','dst','dst_arr','time_cost')\n",
    "edges_info.cache()\n",
    "edges_info.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "######################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#join edges_info with new_timetable to get delay: dst, dst_arr, trip_id, (dst_sq)\n",
    "temp_timetable_to_join = new_timetable.select('trip_id', functions.col('arrival_time').alias('dst_arr'),\n",
    "                                                         functions.col('stop_id').alias('dst'), 'delays')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#delay_sorter = functions.udf(lambda x: sorted(x, reverse=True))\n",
    "#temp_timetable_to_join = temp_timetable_to_join.withColumn('delays', delay_sorter('delays'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "edges_info_w_delay = edges_info.join(temp_timetable_to_join, on = ['trip_id', 'dst_arr', 'dst'], how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+-------+--------+-------+---------+--------------------+\n",
      "|             trip_id| dst_arr|    dst| src_dep|    src|time_cost|              delays|\n",
      "+--------------------+--------+-------+--------+-------+---------+--------------------+\n",
      "|312.TA.26-2-A-j19...|19:34:00|8591093|19:33:00|8591299|       60|[83, 3, 0, 82, 10...|\n",
      "|1548.TA.26-2-A-j1...|19:34:00|8591093|19:32:00|8591105|      120|[83, 3, 0, 82, 10...|\n",
      "|1473.TA.26-2-A-j1...|09:02:00|8590318|09:00:00|8591051|      120|[45, 20, 74, 112,...|\n",
      "|1502.TA.26-2-A-j1...|14:39:00|8590318|14:38:00|8591051|       60|[93, 155, 15, 51,...|\n",
      "|229.TA.26-2-A-j19...|08:18:00|8576197|08:17:00|8576196|       60|[67, 34, 6, 13, 6...|\n",
      "|1475.TA.26-2-A-j1...|08:18:00|8576197|08:17:00|8576198|       60|[67, 34, 6, 13, 6...|\n",
      "|462.TA.26-2-A-j19...|09:43:00|8576199|09:42:00|8576198|       60|[163, 72, 42, 42,...|\n",
      "|1541.TA.26-2-A-j1...|13:29:00|8591165|13:27:00|8591222|      120|[157, 38, 142, 52...|\n",
      "|421.TA.26-2-A-j19...|11:20:00|8576198|11:19:00|8576197|       60|[9, 18, 97, 96, 1...|\n",
      "|1315.TA.26-2-A-j1...|12:05:00|8591222|12:04:00|8591138|       60|[50, 59, 48, 9, 5...|\n",
      "|336.TA.26-2-A-j19...|16:46:00|8591222|16:44:00|8591165|      120|                  []|\n",
      "|1107.TA.26-2-A-j1...|19:13:00|8591252|19:12:00|8591138|       60|[63, 22, 72, 72, ...|\n",
      "|312.TA.26-2-A-j19...|19:19:00|8591252|19:18:00|8591138|       60|[36, 75, 135, 36,...|\n",
      "|422.TA.26-2-A-j19...|10:45:00|8591258|10:44:00|8591051|       60|[53, 24, 13, 32, ...|\n",
      "|1383.TA.26-2-A-j1...|10:45:00|8591258|10:44:00|8591165|       60|[53, 24, 13, 32, ...|\n",
      "|399.TA.26-2-A-j19...|12:12:00|8591381|12:11:00|8591079|       60|[82, 110, 118, 48...|\n",
      "|364.TA.26-2-A-j19...|14:12:00|8591381|14:11:00|8591079|       60|[39, 57, 100, 172...|\n",
      "|1381.TA.26-2-A-j1...|16:44:00|8576200|16:43:00|8576182|       60|[82, 33, 6, 8, 12...|\n",
      "|1549.TA.26-2-A-j1...|19:15:00|8576200|19:14:00|8576182|       60|[0, 0, 0, 0, 122,...|\n",
      "|1357.TA.26-2-A-j1...|17:36:00|8591218|17:34:00|8591079|      120|[63, 10, 8, 198, ...|\n",
      "+--------------------+--------+-------+--------+-------+---------+--------------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "edges_info_w_delay.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "######################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+---+---+-------+---------+\n",
      "|trip_id|src_dep|src|dst|dst_arr|time_cost|\n",
      "+-------+-------+---+---+-------+---------+\n",
      "+-------+-------+---+---+-------+---------+"
     ]
    }
   ],
   "source": [
    "# check if any time_cost smaller than 0 \n",
    "edges_info.filter(col('time_cost') < 0).show(20,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Same station transfer network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def one_more_stops(x):\n",
    "    \"\"\"\n",
    "    filter stations with more stops\n",
    "    \"\"\"\n",
    "    return len(x) > 1\n",
    "one_more_stops_udf = udf(one_more_stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86"
     ]
    }
   ],
   "source": [
    "# filter stations with more stops\n",
    "more_stops_stations = stations.withColumn('more_stops',one_more_stops_udf('stops')).filter(col('more_stops') == 'true')\n",
    "more_stops_stations.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+-----------------+----------------+----------+\n",
      "|       station_name|               stops|      station_lat|     station_lon|more_stops|\n",
      "+-------------------+--------------------+-----------------+----------------+----------+\n",
      "|Winkel am Zürichsee|[8503111, 8503111...|47.29724984915355|8.59897932798565|      true|\n",
      "+-------------------+--------------------+-----------------+----------------+----------+\n",
      "only showing top 1 row"
     ]
    }
   ],
   "source": [
    "more_stops_stations.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "same_stations_df = more_stops_stations.select('station_name','stops').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           dst          src\n",
      "0  8503111:0:1      8503111\n",
      "1      8503111  8503111:0:1\n",
      "2  8503111:0:2      8503111\n",
      "3      8503111  8503111:0:2\n",
      "4     8503111P      8503111"
     ]
    }
   ],
   "source": [
    "# build double direction edge between two stops in one stations\n",
    "# this means stops have a edge can be transferred in one stations\n",
    "from itertools import combinations \n",
    "same_stations_transfer_nw = {'src':[],'dst':[]}\n",
    "for record in same_stations_df.values:\n",
    "    stops = [x.strip().encode('ascii', 'ignore') for x in record[1]]\n",
    "    comb = combinations(stops, 2) \n",
    "    for c in comb:\n",
    "        same_stations_transfer_nw['src'].append(c[0])\n",
    "        same_stations_transfer_nw['src'].append(c[1])\n",
    "        same_stations_transfer_nw['dst'].append(c[1])\n",
    "        same_stations_transfer_nw['dst'].append(c[0])\n",
    "same_stations_transfer_nw_df = pd.DataFrame(same_stations_transfer_nw)\n",
    "same_stations_transfer_nw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           dst          src  ...   src_dep   dst_arr\n",
      "0  8503111:0:1      8503111  ...  00:00:00  00:00:00\n",
      "1      8503111  8503111:0:1  ...  00:00:00  00:00:00\n",
      "2  8503111:0:2      8503111  ...  00:00:00  00:00:00\n",
      "3      8503111  8503111:0:2  ...  00:00:00  00:00:00\n",
      "4     8503111P      8503111  ...  00:00:00  00:00:00\n",
      "\n",
      "[5 rows x 6 columns]"
     ]
    }
   ],
   "source": [
    "# add infomation and columns need to be the same with the network built by time table\n",
    "same_stations_transfer_nw_df['trip_id'] = \"sameStationsTransfer\"\n",
    "same_stations_transfer_nw_df['time_cost'] = 120\n",
    "same_stations_transfer_nw_df['src_dep'] = \"00:00:00\"\n",
    "same_stations_transfer_nw_df['dst_arr'] = \"00:00:00\"\n",
    "same_stations_transfer_nw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+--------------------+---------+--------+--------+\n",
      "|        dst|        src|             trip_id|time_cost| src_dep| dst_arr|\n",
      "+-----------+-----------+--------------------+---------+--------+--------+\n",
      "|8503111:0:1|    8503111|sameStationsTransfer|      120|00:00:00|00:00:00|\n",
      "|    8503111|8503111:0:1|sameStationsTransfer|      120|00:00:00|00:00:00|\n",
      "|8503111:0:2|    8503111|sameStationsTransfer|      120|00:00:00|00:00:00|\n",
      "|    8503111|8503111:0:2|sameStationsTransfer|      120|00:00:00|00:00:00|\n",
      "|   8503111P|    8503111|sameStationsTransfer|      120|00:00:00|00:00:00|\n",
      "|    8503111|   8503111P|sameStationsTransfer|      120|00:00:00|00:00:00|\n",
      "|8503111:0:2|8503111:0:1|sameStationsTransfer|      120|00:00:00|00:00:00|\n",
      "|8503111:0:1|8503111:0:2|sameStationsTransfer|      120|00:00:00|00:00:00|\n",
      "|   8503111P|8503111:0:1|sameStationsTransfer|      120|00:00:00|00:00:00|\n",
      "|8503111:0:1|   8503111P|sameStationsTransfer|      120|00:00:00|00:00:00|\n",
      "|   8503111P|8503111:0:2|sameStationsTransfer|      120|00:00:00|00:00:00|\n",
      "|8503111:0:2|   8503111P|sameStationsTransfer|      120|00:00:00|00:00:00|\n",
      "|8503016:0:2|8503016:0:1|sameStationsTransfer|      120|00:00:00|00:00:00|\n",
      "|8503016:0:1|8503016:0:2|sameStationsTransfer|      120|00:00:00|00:00:00|\n",
      "|8503016:0:3|8503016:0:1|sameStationsTransfer|      120|00:00:00|00:00:00|\n",
      "|8503016:0:1|8503016:0:3|sameStationsTransfer|      120|00:00:00|00:00:00|\n",
      "|8503016:0:4|8503016:0:1|sameStationsTransfer|      120|00:00:00|00:00:00|\n",
      "|8503016:0:1|8503016:0:4|sameStationsTransfer|      120|00:00:00|00:00:00|\n",
      "|   8503016P|8503016:0:1|sameStationsTransfer|      120|00:00:00|00:00:00|\n",
      "|8503016:0:1|   8503016P|sameStationsTransfer|      120|00:00:00|00:00:00|\n",
      "+-----------+-----------+--------------------+---------+--------+--------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "same_stations_transfer_spdf = spark.createDataFrame(same_stations_transfer_nw_df)\n",
    "same_stations_transfer_spdf = same_stations_transfer_spdf.withColumn('src_dep',from_unixtime(unix_timestamp('src_dep', 'HH:mm:ss'), 'HH:mm:ss'))\n",
    "same_stations_transfer_spdf = same_stations_transfer_spdf.withColumn('dst_arr',from_unixtime(unix_timestamp('dst_arr', 'HH:mm:ss'), 'HH:mm:ss'))\n",
    "same_stations_transfer_spdf.show()\n",
    "### TODO: add fake delay column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def dummy(x):\n",
    "    return []\n",
    "\n",
    "dummier = functions.udf(lambda x: dummy(x), ArrayType(LongType()))\n",
    "\n",
    "same_stations_transfer_spdf_w_delay = same_stations_transfer_spdf.withColumn('delays', dummier('time_cost'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# union all to one dataframe\n",
    "edges_with_sameStationTransfer_w_delay = edges_info_w_delay.unionByName(same_stations_transfer_spdf_w_delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#edges_with_sameStationTransfer_w_delay.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# union all to one dataframe\n",
    "edges_with_sameStationTransfer = edges_info.unionByName(same_stations_transfer_spdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187032"
     ]
    }
   ],
   "source": [
    "edges_info.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2082"
     ]
    }
   ],
   "source": [
    "same_stations_transfer_spdf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189114"
     ]
    }
   ],
   "source": [
    "edges_with_sameStationTransfer.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Walking network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+----------------+----------------+\n",
      "|    stop_id|           stop_name|        stop_lat|        stop_lon|\n",
      "+-----------+--------------------+----------------+----------------+\n",
      "|    8575921|Effretikon, Linde...|47.4260215925169|8.69948284198693|\n",
      "|    8590727|Oberengstringen, ...|47.4104852703573|8.45874332896223|\n",
      "|    8503091|   Zürich Giesshübel|47.3624553927874|8.52184997768041|\n",
      "|    8502270|         Bergfrieden|47.3977111751049|8.39908621093555|\n",
      "|    8573234|   Kloten, Hohrainli|47.4596193089001|8.58166879245825|\n",
      "|    8590759|Regensdorf, Stras...|47.4397123662621|8.46168081994171|\n",
      "|    8575941|    Lindau, Eschikon|47.4480782093562|8.68228908744649|\n",
      "|    8591181|Zürich, Heerenwiesen|47.4047157270536|8.57633279966984|\n",
      "|    8576248|     Watt, Geerenweg|47.4390014816685|8.47723964066482|\n",
      "|    8591136|  Zürich, Frankental|47.4057006674825|8.48137189097235|\n",
      "|    8591832|Pfaffhausen, Müseren|47.3626987847054|8.61754750491098|\n",
      "|8573213:0:C|Zürich Flughafen,...|47.4449009252815|8.57069137968479|\n",
      "|8573205:0:D|Zürich Flughafen,...|47.4506842895344|8.56372943623189|\n",
      "|    8580443|Glattbrugg, Rieth...|47.4363765938092|8.56892169857482|\n",
      "|8575918:0:C| Effretikon, Bahnhof|47.4253834536134|8.68615184316874|\n",
      "|    8590715|       Maur, Platten|47.3433577972773|8.66072053747178|\n",
      "|    8503062|                 Egg|47.3015051696329|8.68961035701308|\n",
      "|    8503168|Riedikon, Chis/Na...|47.3263540285675|8.71009194549386|\n",
      "|    8502508|Spreitenbach, Rai...|47.4154457211288|8.37718528430566|\n",
      "|    8590830|Thalwil, Zehntens...|47.2898989435306|8.57052069978078|\n",
      "+-----------+--------------------+----------------+----------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "# to construct walking network, we need to construct vertex information dataframe\n",
    "all_info = trip_info.select('trip_id','stop_id','stop_name','stop_lat','stop_lon','arrival_time', 'departure_time')\n",
    "vertex_info = all_info.select('stop_id','stop_name','stop_lat','stop_lon').distinct()\n",
    "vertex_info.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def convert_to_hour_trip_dict(x):\n",
    "    \"\"\"\n",
    "    for each vertex, record the time of the trip it has\n",
    "    \"\"\"\n",
    "    hour_trip = dict()\n",
    "    for tmp in x:\n",
    "        if tmp[0] in hour_trip:\n",
    "            hour_trip[tmp[0]].append(tmp[1])\n",
    "        else:\n",
    "            hour_trip[tmp[0]] = [tmp[1]]\n",
    "    return hour_trip\n",
    "hour_trip_dict = udf(convert_to_hour_trip_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# add stop infomation according to timetable\n",
    "vertex_arrhour = all_info.withColumn('arr_hour',functions.hour(all_info.arrival_time)).groupBy('stop_id').agg(collect_list(array('arr_hour','trip_id')))\\\n",
    "                         .withColumnRenamed(\"collect_list(array(arr_hour, trip_id))\", \"arr_hour\").withColumn('arr_hourtrip',hour_trip_dict('arr_hour')).select('stop_id','arr_hourtrip')\n",
    "vertex_dephour = all_info.withColumn('dep_hour',functions.hour(all_info.departure_time)).groupBy('stop_id').agg(collect_list(array('dep_hour','trip_id')))\\\n",
    "                         .withColumnRenamed(\"collect_list(array(dep_hour, trip_id))\", \"dep_hour\").withColumn('dep_hourtrip',hour_trip_dict('dep_hour')).select('stop_id','dep_hourtrip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+----------------+----------------+--------------------+--------------------+\n",
      "|    stop_id|           stop_name|        stop_lat|        stop_lon|        arr_hourtrip|        dep_hourtrip|\n",
      "+-----------+--------------------+----------------+----------------+--------------------+--------------------+\n",
      "|    8575921|Effretikon, Linde...|47.4260215925169|8.69948284198693|{11=[618.TA.26-65...|{11=[618.TA.26-65...|\n",
      "|    8590727|Oberengstringen, ...|47.4104852703573|8.45874332896223|{11=[259.TA.26-30...|{11=[259.TA.26-30...|\n",
      "|    8503091|   Zürich Giesshübel|47.3624553927874|8.52184997768041|{11=[73.TA.26-4-B...|{11=[73.TA.26-4-B...|\n",
      "|    8502270|         Bergfrieden|47.3977111751049|8.39908621093555|{11=[115.TA.1-17-...|{11=[115.TA.1-17-...|\n",
      "|    8573234|   Kloten, Hohrainli|47.4596193089001|8.58166879245825|{11=[120.TA.26-73...|{11=[120.TA.26-73...|\n",
      "|    8590759|Regensdorf, Stras...|47.4397123662621|8.46168081994171|{11=[21.TA.26-452...|{11=[21.TA.26-452...|\n",
      "|    8575941|    Lindau, Eschikon|47.4480782093562|8.68228908744649|{11=[147.TA.26-65...|{11=[147.TA.26-65...|\n",
      "|    8591181|Zürich, Heerenwiesen|47.4047157270536|8.57633279966984|{11=[3220.TA.26-9...|{11=[3220.TA.26-9...|\n",
      "|    8576248|     Watt, Geerenweg|47.4390014816685|8.47723964066482|{11=[214.TA.26-48...|{11=[214.TA.26-48...|\n",
      "|    8591136|  Zürich, Frankental|47.4057006674825|8.48137189097235|{11=[1953.TA.26-1...|{11=[1953.TA.26-1...|\n",
      "|    8591832|Pfaffhausen, Müseren|47.3626987847054|8.61754750491098|{11=[319.TA.26-70...|{11=[319.TA.26-70...|\n",
      "|8573213:0:C|Zürich Flughafen,...|47.4449009252815|8.57069137968479|{11=[172.TA.26-76...|{11=[172.TA.26-76...|\n",
      "|8573205:0:D|Zürich Flughafen,...|47.4506842895344|8.56372943623189|{11=[64.TA.26-733...|{11=[64.TA.26-733...|\n",
      "|    8580443|Glattbrugg, Rieth...|47.4363765938092|8.56892169857482|{11=[1326.TA.26-7...|{11=[1326.TA.26-7...|\n",
      "|8575918:0:C| Effretikon, Bahnhof|47.4253834536134|8.68615184316874|{11=[163.TA.26-72...|{11=[163.TA.26-72...|\n",
      "|    8590715|       Maur, Platten|47.3433577972773|8.66072053747178|{11=[317.TA.26-70...|{11=[317.TA.26-70...|\n",
      "|    8503062|                 Egg|47.3015051696329|8.68961035701308|{11=[281.TA.26-18...|{11=[281.TA.26-18...|\n",
      "|    8503168|Riedikon, Chis/Na...|47.3263540285675|8.71009194549386|{11=[211.TA.26-84...|{11=[211.TA.26-84...|\n",
      "|    8502508|Spreitenbach, Rai...|47.4154457211288|8.37718528430566|{11=[593.TA.26-30...|{11=[593.TA.26-30...|\n",
      "|    8590830|Thalwil, Zehntens...|47.2898989435306|8.57052069978078|{11=[1174.TA.26-1...|{11=[1174.TA.26-1...|\n",
      "+-----------+--------------------+----------------+----------------+--------------------+--------------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "# add arrival & departure hour information to vertex\n",
    "vertex_info = vertex_info.join(vertex_arrhour,on =['stop_id'],how='left')\n",
    "vertex_info = vertex_info.join(vertex_dephour,on =['stop_id'],how='left')\n",
    "vertex_info.cache()\n",
    "vertex_info.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+----------------+----------------+--------------------+--------------------+\n",
      "|     id|           stop_name|        stop_lat|        stop_lon|        arr_hourtrip|        dep_hourtrip|\n",
      "+-------+--------------------+----------------+----------------+--------------------+--------------------+\n",
      "|8575921|Effretikon, Linde...|47.4260215925169|8.69948284198693|{11=[618.TA.26-65...|{11=[618.TA.26-65...|\n",
      "|8590727|Oberengstringen, ...|47.4104852703573|8.45874332896223|{11=[259.TA.26-30...|{11=[259.TA.26-30...|\n",
      "|8503091|   Zürich Giesshübel|47.3624553927874|8.52184997768041|{11=[73.TA.26-4-B...|{11=[73.TA.26-4-B...|\n",
      "|8502270|         Bergfrieden|47.3977111751049|8.39908621093555|{11=[115.TA.1-17-...|{11=[115.TA.1-17-...|\n",
      "|8573234|   Kloten, Hohrainli|47.4596193089001|8.58166879245825|{11=[120.TA.26-73...|{11=[120.TA.26-73...|\n",
      "|8590759|Regensdorf, Stras...|47.4397123662621|8.46168081994171|{11=[21.TA.26-452...|{11=[21.TA.26-452...|\n",
      "|8575941|    Lindau, Eschikon|47.4480782093562|8.68228908744649|{11=[147.TA.26-65...|{11=[147.TA.26-65...|\n",
      "|8591181|Zürich, Heerenwiesen|47.4047157270536|8.57633279966984|{11=[3220.TA.26-9...|{11=[3220.TA.26-9...|\n",
      "|8576248|     Watt, Geerenweg|47.4390014816685|8.47723964066482|{11=[214.TA.26-48...|{11=[214.TA.26-48...|\n",
      "|8591136|  Zürich, Frankental|47.4057006674825|8.48137189097235|{11=[1953.TA.26-1...|{11=[1953.TA.26-1...|\n",
      "+-------+--------------------+----------------+----------------+--------------------+--------------------+\n",
      "only showing top 10 rows"
     ]
    }
   ],
   "source": [
    "# rename stop_id as id\n",
    "vertex_info = vertex_info.select(col('stop_id').alias('id'),'stop_name','stop_lat','stop_lon','arr_hourtrip','dep_hourtrip')\n",
    "vertex_info.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1243"
     ]
    }
   ],
   "source": [
    "vertex_info.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------+----------------+-----------+----------------+----------------+\n",
      "|    id1|       stop_lat1|       stop_lon1|        id2|       stop_lat2|       stop_lon2|\n",
      "+-------+----------------+----------------+-----------+----------------+----------------+\n",
      "|8575921|47.4260215925169|8.69948284198693|    8575921|47.4260215925169|8.69948284198693|\n",
      "|8575921|47.4260215925169|8.69948284198693|    8590727|47.4104852703573|8.45874332896223|\n",
      "|8575921|47.4260215925169|8.69948284198693|    8503091|47.3624553927874|8.52184997768041|\n",
      "|8575921|47.4260215925169|8.69948284198693|    8502270|47.3977111751049|8.39908621093555|\n",
      "|8575921|47.4260215925169|8.69948284198693|    8573234|47.4596193089001|8.58166879245825|\n",
      "|8575921|47.4260215925169|8.69948284198693|    8590759|47.4397123662621|8.46168081994171|\n",
      "|8575921|47.4260215925169|8.69948284198693|    8575941|47.4480782093562|8.68228908744649|\n",
      "|8575921|47.4260215925169|8.69948284198693|    8591181|47.4047157270536|8.57633279966984|\n",
      "|8575921|47.4260215925169|8.69948284198693|    8576248|47.4390014816685|8.47723964066482|\n",
      "|8575921|47.4260215925169|8.69948284198693|    8591136|47.4057006674825|8.48137189097235|\n",
      "|8575921|47.4260215925169|8.69948284198693|    8591832|47.3626987847054|8.61754750491098|\n",
      "|8575921|47.4260215925169|8.69948284198693|8573213:0:C|47.4449009252815|8.57069137968479|\n",
      "|8575921|47.4260215925169|8.69948284198693|8573205:0:D|47.4506842895344|8.56372943623189|\n",
      "|8575921|47.4260215925169|8.69948284198693|    8580443|47.4363765938092|8.56892169857482|\n",
      "|8575921|47.4260215925169|8.69948284198693|8575918:0:C|47.4253834536134|8.68615184316874|\n",
      "|8575921|47.4260215925169|8.69948284198693|    8590715|47.3433577972773|8.66072053747178|\n",
      "|8575921|47.4260215925169|8.69948284198693|    8503062|47.3015051696329|8.68961035701308|\n",
      "|8575921|47.4260215925169|8.69948284198693|    8503168|47.3263540285675|8.71009194549386|\n",
      "|8575921|47.4260215925169|8.69948284198693|    8502508|47.4154457211288|8.37718528430566|\n",
      "|8575921|47.4260215925169|8.69948284198693|    8590830|47.2898989435306|8.57052069978078|\n",
      "+-------+----------------+----------------+-----------+----------------+----------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "# cross product of vertex list to build stops pair \n",
    "vertex_id = vertex_info.select('id')\n",
    "vertex_loc1 = vertex_info.select(col('id').alias('id1'),col('stop_lat').alias('stop_lat1'),col('stop_lon').alias('stop_lon1'))\n",
    "vertex_loc2 = vertex_info.select(col('id').alias('id2'),col('stop_lat').alias('stop_lat2'),col('stop_lon').alias('stop_lon2'))\n",
    "vid_crossproduct = vertex_loc1.crossJoin(vertex_loc2)\n",
    "vid_crossproduct.cache()\n",
    "vid_crossproduct.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------+----------------+-----------+----------------+----------------+-------------------+------------------+\n",
      "|    id1|       stop_lat1|       stop_lon1|        id2|       stop_lat2|       stop_lon2|           distance|         time_cost|\n",
      "+-------+----------------+----------------+-----------+----------------+----------------+-------------------+------------------+\n",
      "|8575921|47.4260215925169|8.69948284198693|    8575920|47.4290480888166|8.69659924992451|0.40038442297354065| 480.4613075682488|\n",
      "|8575921|47.4260215925169|8.69948284198693|    8503370|47.4238215000378| 8.7010638768872| 0.2720205125095378| 326.4246150114454|\n",
      "|8575921|47.4260215925169|8.69948284198693|    8503372|47.4271216042743|8.69411989973999|0.42157359412504647|505.88831295005576|\n",
      "|8590727|47.4104852703573|8.45874332896223|    8590728|47.4091295756792|8.46260608468448| 0.3274408398465013| 392.9290078158016|\n",
      "|8590727|47.4104852703573|8.45874332896223|    8590833|47.4122360710415|8.45316479104707|0.46272544507973606| 555.2705340956833|\n",
      "|8503091|47.3624553927874|8.52184997768041|    8591415|47.3614818138862|8.52574866601403| 0.3129668838234156| 375.5602605880987|\n",
      "|8503091|47.3624553927874|8.52184997768041|    8503051|47.3626318520399|8.51842739644744| 0.2585299157113723| 310.2358988536467|\n",
      "|8503091|47.3624553927874|8.52184997768041|    8591366|47.3600640074787|8.52303575385561| 0.2805083480055939|336.61001760671263|\n",
      "|8502270|47.3977111751049|8.39908621093555|    8590220|47.3992799838144|8.39447785352737|0.38825447672557256|465.90537207068706|\n",
      "|8502270|47.3977111751049|8.39908621093555|8502186:0:1|47.3934666445388|8.39894248049007|0.47209425057180804| 566.5131006861697|\n",
      "|8502270|47.3977111751049|8.39908621093555|    8517376| 47.401991845291|8.40090979096256|0.49538225699051697| 594.4587083886204|\n",
      "|8502270|47.3977111751049|8.39908621093555|8502186:0:2|47.3935274568464|8.39894248049007| 0.4653340270947321| 558.4008325136786|\n",
      "|8502270|47.3977111751049|8.39908621093555|    8590521|47.4017364741549|8.39637329877713|0.49196792365518827| 590.3615083862259|\n",
      "|8573234|47.4596193089001|8.58166879245825|    8573232|47.4631236572114|8.58326779366421| 0.4077861768905206|489.34341226862466|\n",
      "|8573234|47.4596193089001|8.58166879245825|    8573233|47.4576696483172|8.58039318475463|0.23705717734881743|284.46861281858094|\n",
      "|8590759|47.4397123662621|8.46168081994171|    8576279|47.4416080115536|8.46590290177766| 0.3811251186605658|457.35014239267895|\n",
      "|8590759|47.4397123662621|8.46168081994171|    8590755|47.4394328743198|8.45653347336299| 0.3883703128770076| 466.0443754524091|\n",
      "|8590759|47.4397123662621|8.46168081994171|    8590756|47.4360302446601| 8.4644296647115| 0.4586703219390378| 550.4043863268454|\n",
      "|8590759|47.4397123662621|8.46168081994171|    8576270|47.4375067699125| 8.4612136959939|0.24775471021321194|297.30565225585434|\n",
      "|8590759|47.4397123662621|8.46168081994171|    8576269|47.4383574240857| 8.4647261087553| 0.2741458924076102| 328.9750708891323|\n",
      "+-------+----------------+----------------+-----------+----------------+----------------+-------------------+------------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "# compute distance between two stops to filter out stops which can be reachable to each other on foot\n",
    "# we consider stops with distance < 500m are reachable by walk \n",
    "distance_twostops_udf = udf(distance)\n",
    "stops_can_walk = vid_crossproduct.filter(col('id1')!=col('id2')).withColumn('distance',distance_twostops_udf('stop_lon1','stop_lat1','stop_lon2','stop_lat2'))\\\n",
    "                      .filter(col('distance')<0.5).withColumn('time_cost',col('distance')*1000/50*60)\n",
    "stops_can_walk.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+------------------+\n",
      "|    src|        dst|         time_cost|\n",
      "+-------+-----------+------------------+\n",
      "|8575921|    8575920| 480.4613075682488|\n",
      "|8575921|    8503370| 326.4246150114454|\n",
      "|8575921|    8503372|505.88831295005576|\n",
      "|8590727|    8590728| 392.9290078158016|\n",
      "|8590727|    8590833| 555.2705340956833|\n",
      "|8503091|    8591415| 375.5602605880987|\n",
      "|8503091|    8503051| 310.2358988536467|\n",
      "|8503091|    8591366|336.61001760671263|\n",
      "|8502270|    8590220|465.90537207068706|\n",
      "|8502270|8502186:0:1| 566.5131006861697|\n",
      "|8502270|    8517376| 594.4587083886204|\n",
      "|8502270|8502186:0:2| 558.4008325136786|\n",
      "|8502270|    8590521| 590.3615083862259|\n",
      "|8573234|    8573232|489.34341226862466|\n",
      "|8573234|    8573233|284.46861281858094|\n",
      "|8590759|    8576279|457.35014239267895|\n",
      "|8590759|    8590755| 466.0443754524091|\n",
      "|8590759|    8590756| 550.4043863268454|\n",
      "|8590759|    8576270|297.30565225585434|\n",
      "|8590759|    8576269| 328.9750708891323|\n",
      "+-------+-----------+------------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "# construct walking network\n",
    "walking_nw = stops_can_walk.select(col('id1').alias('src'),col('id2').alias('dst'),'time_cost')\n",
    "walking_nw.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+-----+\n",
      "|src|dst|count|\n",
      "+---+---+-----+\n",
      "+---+---+-----+"
     ]
    }
   ],
   "source": [
    "# check if exists two same edge in walking network\n",
    "walking_nw.groupBy('src','dst').count().filter(col('count')>1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6914"
     ]
    }
   ],
   "source": [
    "walking_nw.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+\n",
      "|         src|         dst|\n",
      "+------------+------------+\n",
      "| 8502208:0:4|     8573552|\n",
      "|8503000:0:13|     8591262|\n",
      "|8503000:0:34|8503088:0:21|\n",
      "| 8503000:0:9|     8587349|\n",
      "| 8503011:0:1|     8573710|\n",
      "| 8503508:0:5|     8595511|\n",
      "|     8573504|     8588055|\n",
      "|     8576195|     8530813|\n",
      "|     8576259|     8576258|\n",
      "|     8576283| 8503315:0:3|\n",
      "|     8580438|     8580435|\n",
      "|     8587348|     8591367|\n",
      "|     8587349|8503000:0:34|\n",
      "|     8587420|     8576152|\n",
      "|     8588003|     8588001|\n",
      "|     8588005|     8588007|\n",
      "|     8588078|8503000:0:31|\n",
      "|     8588736|     8580434|\n",
      "|     8590519|     8590520|\n",
      "|     8590529|     8590217|\n",
      "+------------+------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "# stops can be transfer in one station doesn't include in this case\n",
    "# drop them out of the walking network\n",
    "not_in_one_stations = walking_nw.select('src','dst').join(same_stations_transfer_spdf,on=['src','dst'],how=\"leftanti\")\n",
    "not_in_one_stations.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5872"
     ]
    }
   ],
   "source": [
    "not_in_one_stations.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+------------------+\n",
      "|         src|         dst|         time_cost|\n",
      "+------------+------------+------------------+\n",
      "| 8502208:0:4|     8573552| 560.0945691828715|\n",
      "|8503000:0:13|     8591262|  433.763953695952|\n",
      "|8503000:0:34|8503088:0:21|217.12913884881664|\n",
      "| 8503000:0:9|     8587349|227.30588964219046|\n",
      "| 8503011:0:1|     8573710| 69.31110061338293|\n",
      "| 8503508:0:5|     8595511| 345.5078520541618|\n",
      "|     8573504|     8588055| 434.3485394526424|\n",
      "|     8576195|     8530813| 585.6793077043894|\n",
      "|     8576259|     8576258| 339.2625057956586|\n",
      "|     8576283| 8503315:0:3| 540.3562358840627|\n",
      "|     8580438|     8580435|484.39368059408264|\n",
      "|     8587348|     8591367| 488.7278973709142|\n",
      "|     8587349|8503000:0:34|240.32341513504582|\n",
      "|     8587420|     8576152| 528.4816300244935|\n",
      "|     8588003|     8588001| 464.9911865299479|\n",
      "|     8588005|     8588007|436.77478536669275|\n",
      "|     8588078|8503000:0:31|457.38065027456025|\n",
      "|     8588736|     8580434| 345.2813900640017|\n",
      "|     8590519|     8590520| 529.9453271639844|\n",
      "|     8590529|     8590217|183.68946206411454|\n",
      "+------------+------------+------------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "walking_nw = walking_nw.join(not_in_one_stations, on=['src','dst'],how='inner')\n",
    "walking_nw.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5872"
     ]
    }
   ],
   "source": [
    "walking_nw.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+------------------+-------+--------+--------+\n",
      "|         src|         dst|         time_cost|trip_id| src_dep| dst_arr|\n",
      "+------------+------------+------------------+-------+--------+--------+\n",
      "| 8502208:0:4|     8573552| 560.0945691828715|   walk|00:00:00|00:00:00|\n",
      "|8503000:0:13|     8591262|  433.763953695952|   walk|00:00:00|00:00:00|\n",
      "|8503000:0:34|8503088:0:21|217.12913884881664|   walk|00:00:00|00:00:00|\n",
      "| 8503000:0:9|     8587349|227.30588964219046|   walk|00:00:00|00:00:00|\n",
      "| 8503011:0:1|     8573710| 69.31110061338293|   walk|00:00:00|00:00:00|\n",
      "| 8503508:0:5|     8595511| 345.5078520541618|   walk|00:00:00|00:00:00|\n",
      "|     8573504|     8588055| 434.3485394526424|   walk|00:00:00|00:00:00|\n",
      "|     8576195|     8530813| 585.6793077043894|   walk|00:00:00|00:00:00|\n",
      "|     8576259|     8576258| 339.2625057956586|   walk|00:00:00|00:00:00|\n",
      "|     8576283| 8503315:0:3| 540.3562358840627|   walk|00:00:00|00:00:00|\n",
      "|     8580438|     8580435|484.39368059408264|   walk|00:00:00|00:00:00|\n",
      "|     8587348|     8591367| 488.7278973709142|   walk|00:00:00|00:00:00|\n",
      "|     8587349|8503000:0:34|240.32341513504582|   walk|00:00:00|00:00:00|\n",
      "|     8587420|     8576152| 528.4816300244935|   walk|00:00:00|00:00:00|\n",
      "|     8588003|     8588001| 464.9911865299479|   walk|00:00:00|00:00:00|\n",
      "|     8588005|     8588007|436.77478536669275|   walk|00:00:00|00:00:00|\n",
      "|     8588078|8503000:0:31|457.38065027456025|   walk|00:00:00|00:00:00|\n",
      "|     8588736|     8580434| 345.2813900640017|   walk|00:00:00|00:00:00|\n",
      "|     8590519|     8590520| 529.9453271639844|   walk|00:00:00|00:00:00|\n",
      "|     8590529|     8590217|183.68946206411454|   walk|00:00:00|00:00:00|\n",
      "+------------+------------+------------------+-------+--------+--------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "# final walking network\n",
    "### TODO: add delay list column\n",
    "walking_nw = walking_nw.withColumn('trip_id',lit('walk'))\n",
    "walking_nw = walking_nw.withColumn('src_dep',from_unixtime(unix_timestamp(lit('00:00:00'), 'HH:mm:ss'), 'HH:mm:ss'))\n",
    "walking_nw = walking_nw.withColumn('dst_arr',from_unixtime(unix_timestamp(lit('00:00:00'), 'HH:mm:ss'), 'HH:mm:ss'))\n",
    "walking_nw.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def dummy2(x):\n",
    "    return []\n",
    "\n",
    "dummier2 = functions.udf(lambda x: dummy2(x), ArrayType(LongType()))\n",
    "\n",
    "walking_nw_w_delay = walking_nw.withColumn('delays', dummier2('time_cost'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# union all to one dataframe\n",
    "all_edges_info_w_delay = edges_with_sameStationTransfer_w_delay.unionByName(walking_nw_w_delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194986"
     ]
    }
   ],
   "source": [
    "# union all\n",
    "all_edges_info = edges_with_sameStationTransfer.unionByName(walking_nw)\n",
    "all_edges_info.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Save/Load output of this part\n",
    "#all_edges_info.write.format(\"orc\").save(path=\"hdfs:///user/lyan/temp_data/all_edges_info.orc\", mode=\"overwrite\")\n",
    "#all_edges_info_w_delay.write.format(\"orc\").save(path=\"hdfs:///user/lyan/temp_data/all_edges_info_w_delay.orc\", mode=\"overwrite\")\n",
    "#vertex_info.write.format(\"orc\").save(path=\"hdfs:///user/lyan/temp_data/vertex_info.orc\", mode=\"overwrite\")\n",
    "\n",
    "### pre-load saved data, will be used in part IV & V\n",
    "all_edges_info = spark.read.orc(\"hdfs:///user/lyan/temp_data/all_edges_info.orc\")\n",
    "all_edges_info_w_delay = spark.read.orc(\"hdfs:///user/lyan/temp_data/all_edges_info_w_delay.orc\")\n",
    "vertex_info = spark.read.orc(\"hdfs:///user/lyan/temp_data/vertex_info.orc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# convert spark dataframe to pandas dataframe for convenience to feed networkx\n",
    "all_edges_info_df =  all_edges_info.toPandas()\n",
    "all_edges_info_w_delay_df = all_edges_info_w_delay.toPandas()\n",
    "vertex_info_df = vertex_info.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   trip_id   src_dep  ...   dst_arr time_cost\n",
      "0    60.TA.26-2-j19-1.10.R  15:19:00  ...  15:24:00     300.0\n",
      "1   62.TA.26-133-j19-1.2.R  12:00:00  ...  12:02:00     120.0\n",
      "2   62.TA.26-133-j19-1.2.R  12:02:00  ...  12:04:00     120.0\n",
      "3   62.TA.26-133-j19-1.2.R  12:04:00  ...  12:06:00     120.0\n",
      "4  736.TA.26-131-j19-1.7.R  17:07:00  ...  17:08:00      60.0\n",
      "\n",
      "[5 rows x 6 columns]"
     ]
    }
   ],
   "source": [
    "all_edges_info_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     trip_id  ...                                             delays\n",
      "0    312.TA.26-2-A-j19-1.1.H  ...  [83, 3, 0, 82, 10, 111, 40, 0, 6, 55, 1, 84, 1...\n",
      "1  1548.TA.26-2-A-j19-1.24.R  ...  [83, 3, 0, 82, 10, 111, 40, 0, 6, 55, 1, 84, 1...\n",
      "2  1473.TA.26-2-A-j19-1.24.R  ...  [45, 20, 74, 112, 248, 114, 42, 42, 6, 0, 16, ...\n",
      "3  1502.TA.26-2-A-j19-1.24.R  ...  [93, 155, 15, 51, 12, 10, 76, 91, 126, 96, 174...\n",
      "4    229.TA.26-2-A-j19-1.1.H  ...  [67, 34, 6, 13, 62, 38, 107, 36, 47, 110, 6, 2...\n",
      "\n",
      "[5 rows x 7 columns]"
     ]
    }
   ],
   "source": [
    "all_edges_info_w_delay_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id  ...                                       dep_hourtrip\n",
      "0  8576193  ...  {11=[1139.TA.26-5-B-j19-1.23.R, 660.TA.26-15-A...\n",
      "1  8591891  ...  {11=[634.TA.26-303-j19-1.10.R, 418.TA.26-303-j...\n",
      "2  8590223  ...  {11=[323.TA.26-306-j19-1.2.H, 13.TA.1-305-j19-...\n",
      "3  8591283  ...  {11=[2504.TA.26-7-B-j19-1.17.H, 2505.TA.26-7-B...\n",
      "4  8502776  ...  {11=[856.TA.26-140-j19-1.6.H, 855.TA.26-140-j1...\n",
      "\n",
      "[5 rows x 6 columns]"
     ]
    }
   ],
   "source": [
    "vertex_info_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def time2timestamps(time):\n",
    "    \"\"\"\n",
    "    convert time string to time, np.datetime64 need to feed a date\n",
    "    \"\"\"\n",
    "    # time string like \"12:30:00\"\n",
    "    arr_time = np.datetime64(time)\n",
    "    return arr_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#convert string to datetime\n",
    "# This parameter is hardcoded and only used to workaround a numpy limitation \n",
    "# np.datetime64 need to feed a date\n",
    "date = '2000-01-01T'\n",
    "all_edges_info_df['src_dep'] =all_edges_info_df['src_dep'].apply(lambda x: time2timestamps(date + x))\n",
    "all_edges_info_df['dst_arr'] =all_edges_info_df['dst_arr'].apply(lambda x: time2timestamps(date + x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Part IV] Basic Route Planning Algorithm (without uncertainty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our route planning process, we establish several assumptions to limit the search space of our algorithm:\n",
    "1. As the problem aims to find the paths under an area, which is 15km from Zurich HB the farrest, the diameter of this area is 30km, thus we assume the longest distance of a trip is 40km. In this case, the total time cost will not exceed 3 hours according to reality. So we can assume the last stops of expected trip can be reached in 3 hours.\n",
    "2. As the problem ask us to find the latest departure time of a trip, and the latest arrival at the last stops is highly possble to obtain the latest departure time. However, it is not always the case and there are also situations that we arrive a bit earlier but we can still depart later. Therefore, we assume we can get the latest departure time if we just consider the trip which contains the last stop with arrival time 30 minutes before expected one. \n",
    "3. We assume that the total number of transfer will not exceed 4 times including taking other transportations, walk to the other stop(not in the same station) and same station transfer.\n",
    "4. We only consider routes that have historical delay data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: filter out edges satisfied the assumption 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def select_edges(all_edges_info_df, arr_time, start_time):\n",
    "    return all_edges_info_df[(((all_edges_info_df['dst_arr']<=arr_time) & (all_edges_info_df['src_dep']<=arr_time)&\n",
    "                            (all_edges_info_df['dst_arr']>=start_time) & (all_edges_info_df['src_dep']>=start_time) & \n",
    "                            (all_edges_info_df['trip_id'] != \"walk\") & (all_edges_info_df['trip_id'] != \"sameStationsTransfer\"))) |\n",
    "                            ((all_edges_info_df['trip_id'] == \"walk\") | (all_edges_info_df['trip_id'] == \"sameStationsTransfer\"))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: filter out edges satisfied the assumption 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def drop_edges(selected_edges,arr_stop, arg3):\n",
    "    drop_earlyarr = selected_edges[(selected_edges['dst'] == arr_stop) & (selected_edges['dst_arr']<=arg3) & \n",
    "                                (selected_edges['trip_id'] != \"sameStationsTransfer\") &(selected_edges['trip_id'] != \"walk\")]\n",
    "    drop_relatedtrip = drop_earlyarr[drop_earlyarr['trip_id'].isin(drop_earlyarr['trip_id'].unique())]\n",
    "    return selected_edges.drop(list(drop_relatedtrip.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: build edges in each trip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, add edges if they are in one trip (A->B->C => A->C) according to their order  as follows. This will make algorithm more easy to find a path."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./DSLab-1.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, if we go from  D2 to D1, then once we meet A1, we can know that this trip can take us to D1 and the stops in the middle will no longer important. By this way, the algo directly know that D2 to D1 have a path D2-A1-D1, rather than D2-A1-B1-C1-D1, which reduce the size of output and the time of the algo to search for paths."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./DSLab-2.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 7～8 minutes\n",
    "def add_edges_in_one_trip(selected_edges):\n",
    "    new = {\"trip_id\":[],\"src_dep\":[],\"src\":[],\"dst\":[],\"dst_arr\":[],\"time_cost\":[]}\n",
    "    for t_id in selected_edges['trip_id'].unique():\n",
    "        if t_id == \"sameStationsTransfer\" or t_id == \"walk\":\n",
    "            continue\n",
    "        tmp = selected_edges[selected_edges['trip_id'] == t_id].sort_values('src_dep')\n",
    "        if len(tmp) == 1:\n",
    "            continue\n",
    "        trip_id = t_id\n",
    "        for i in range(len(tmp.values)):\n",
    "            if i+1 == (len(tmp.values) - 1):\n",
    "                break\n",
    "            src_dep = tmp.values[i][1]\n",
    "            src = tmp.values[i][2]\n",
    "            time_cost = tmp.values[i][-1]\n",
    "            for j in range(i+1,len(tmp.values)):\n",
    "                dst = tmp.values[j][-3]\n",
    "                dst_arr = tmp.values[j][-2]\n",
    "                time_cost += tmp.values[j][-1]\n",
    "                new['trip_id'].append(trip_id)\n",
    "                new['src_dep'].append(src_dep)\n",
    "                new['src'].append(src)\n",
    "                new['dst'].append(dst)\n",
    "                new['dst_arr'].append(dst_arr)\n",
    "                new['time_cost'].append(time_cost)\n",
    "    return pd.DataFrame(new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: apply assumption 3\n",
    "\n",
    "feed to networkx, use n-depth (cutoff) DFS to find paths with length <=n.\n",
    "\n",
    "Based on the assumption, cutoff here set to be 4, based on the assumption 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def find_connected_path(new_graph_edges,dep_stop,arr_stop):\n",
    "    G = nx.from_pandas_edgelist(\n",
    "            new_graph_edges,\n",
    "            'src',\n",
    "            'dst', ['src_dep', 'dst_arr', 'time_cost', \"trip_id\"],\n",
    "            create_using=nx.DiGraph)\n",
    "    candidates = nx.all_simple_paths(G, dep_stop, arr_stop, cutoff=4)\n",
    "    paths = []\n",
    "    for x in candidates:\n",
    "    #     print(x)\n",
    "        paths.append(x)\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Rebuild path using greedy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After getting the possible paths from the n-depth DFS, we need to consider the connection in terms of time because the algo just consider the connection of space. We need to deduce the departure time of the first stop starting from the last stop. Therefore, we rebuild the path by greedy, choose the  trip with the latest departure but can also catch the next trip. We deduce backwards until it reach the first stop or it cannot find path because it cannot find a previous trip that can ensure us to catch this trip. (e.g. A->B->C, B->C we deduce we depart from B at 12:13, but A->B, we can just arrive at B at 12:15, then this path fail). The followin graph shows the process of deduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./DSLab-3.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# rebuild path by greedily, start from the last stop in the path, choose the trip with the latest arrival and deduce backwards \n",
    "def build_path_greedy(paths, new_graph_edges, arr_time):\n",
    "    build_path = {\"src_dep\":[],\"paths_info\":[],\"dst_arr\":[],\"time_cost\":[]}\n",
    "    for specific_path in paths:\n",
    "        current_dep = arr_time\n",
    "        real_arr_time = arr_time\n",
    "        paths_info = []\n",
    "        catch=True\n",
    "        total_time_cost = 0\n",
    "        for i in range(len(specific_path)-1,0,-1):\n",
    "            src = specific_path[i-1]\n",
    "            dst = specific_path[i]\n",
    "\n",
    "            tmp_df = new_graph_edges[(new_graph_edges['src'] == src) & (new_graph_edges['dst'] == dst)]\n",
    "            if \"sameStationsTransfer\" in tmp_df['trip_id'].values:\n",
    "                same_dep = current_dep - np.timedelta64(120, 's')\n",
    "                info = {\"src\":src,\"src_dep\":same_dep,\"dst\":dst,\"dst_arr\":current_dep,\"trip_id\":\"sameStationTransfer\"}\n",
    "                paths_info.append(info)\n",
    "                current_dep = same_dep\n",
    "                total_time_cost += 120\n",
    "            elif 'walk' not in tmp_df['trip_id'].values:\n",
    "                try:\n",
    "                    tmp = tmp_df[tmp_df['dst_arr'] <= current_dep].sort_values('src_dep',ascending = False).iloc[0]\n",
    "                    if i == len(paths[0]) - 1:\n",
    "                        real_arr_time = tmp['dst_arr']\n",
    "                    current_dep = tmp['src_dep']\n",
    "                    info = {\"src\":src,\"src_dep\":tmp['src_dep'],\"dst\":dst,\"dst_arr\":tmp['dst_arr'],\"trip_id\":tmp['trip_id']}\n",
    "                    paths_info.append(info)\n",
    "                    total_time_cost += tmp['time_cost']\n",
    "                except:\n",
    "                    # cannot catch the transportation from the last stop\n",
    "                    catch=False\n",
    "                    print(specific_path)\n",
    "                    break\n",
    "            else: \n",
    "                time_cost = tmp_df[tmp_df['trip_id'] == 'walk']['time_cost'].values[0]\n",
    "                walk_current_dep = current_dep - np.timedelta64(int(np.ceil(time_cost)), 's')\n",
    "                if len(tmp_df) > 1:\n",
    "                    try:\n",
    "                        tmp = tmp_df[(tmp_df['trip_id'] != 'walk') &\n",
    "                                     (tmp_df['dst_arr'] <= current_dep)].sort_values('src_dep',ascending = False).iloc[0]\n",
    "                        tp_current_dep = tmp['src_dep']\n",
    "                    except:\n",
    "                        # cannot catch the transportation from the last stop\n",
    "                        catch=False\n",
    "                        print(specific_path)\n",
    "                        break\n",
    "                    if walk_current_dep < tp_current_dep:\n",
    "                        if i == len(paths[0]) - 1:\n",
    "                            real_arr_time = tmp['dst_arr']\n",
    "                        info = {\"src\":src,\"src_dep\":tp_current_dep,\"dst\":dst,\"dst_arr\":tmp['dst_arr'],\"trip_id\":tmp['trip_id']}\n",
    "                        paths_info.append(info)\n",
    "                        current_dep = tp_current_dep\n",
    "                        total_time_cost += tmp['time_cost']\n",
    "                    else:\n",
    "                        info = {\"src\":src,\"src_dep\":walk_current_dep,\"dst\":dst,\"dst_arr\":current_dep,\"trip_id\":'walk'}\n",
    "                        paths_info.append(info)\n",
    "                        current_dep = walk_current_dep\n",
    "                        total_time_cost += time_cost\n",
    "                else:\n",
    "                    info = {\"src\":src,\"src_dep\":walk_current_dep,\"dst\":dst,\"dst_arr\":current_dep,\"trip_id\":'walk'}\n",
    "                    paths_info.append(info)\n",
    "                    current_dep = walk_current_dep\n",
    "                    total_time_cost += time_cost\n",
    "        if(catch):\n",
    "            build_path[\"src_dep\"].append(current_dep)\n",
    "            build_path[\"paths_info\"].append(paths_info[::-1])\n",
    "            build_path[\"dst_arr\"].append(real_arr_time)\n",
    "            build_path[\"time_cost\"].append(total_time_cost)\n",
    "    return build_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get all routes\n",
    "def get_routes(all_edges_info_df, dep_stop, arr_stop, arr_time):\n",
    "    ### Ignore it\n",
    "    # This parameter is hardcoded and only used to workaround a numpy limitation \n",
    "    # np.datetime64 need to feed a date\n",
    "    date = '2000-01-01T'\n",
    "\n",
    "    arr_time = time2timestamps(date + arr_time)\n",
    "    delta = np.timedelta64(3, 'h')\n",
    "    start_time = arr_time - delta\n",
    "\n",
    "    # step 1\n",
    "    selected_edges_tmp = select_edges(all_edges_info_df, arr_time, start_time)\n",
    "\n",
    "    # step 2\n",
    "    arg3 = arr_time - np.timedelta64(30, 'm')\n",
    "    selected_edges = drop_edges(selected_edges_tmp, arr_stop, arg3)\n",
    "\n",
    "    # 7～8minutes\n",
    "    # step 3\n",
    "    new_selected = add_edges_in_one_trip(selected_edges)\n",
    "    new_graph_edges = pd.concat([selected_edges,new_selected], sort=True)\n",
    "\n",
    "    # step 4\n",
    "    paths = find_connected_path(new_graph_edges,dep_stop,arr_stop)\n",
    "\n",
    "    # 15minutes\n",
    "    # step 5\n",
    "    build_path = build_path_greedy(paths, new_graph_edges, arr_time)\n",
    "    build_path_df = pd.DataFrame(build_path)\n",
    "    \n",
    "    return build_path_df\n",
    "\n",
    "# print top N routes\n",
    "def print_topN_routes(n, build_path_df):\n",
    "    # choose the first N route as final result (latest depature time, if there are several candidates which have the same depature time , choose the one use less time cost)\n",
    "    #### Ignore the date in the output ####\n",
    "    firstN = build_path_df.sort_values(['src_dep','time_cost'],ascending=[False,True]).iloc[:n]\n",
    "    for path in firstN['paths_info'].values:\n",
    "        print(\"Route:\")\n",
    "        # for walk to correct time\n",
    "        next_dep = path[0]['src_dep']\n",
    "        for partial_path in path:\n",
    "            src = partial_path['src']\n",
    "            try:\n",
    "                src_name = vertex_info_df[vertex_info_df['id'] == src]['stop_name'].values[0].encode('utf-8')\n",
    "            except:\n",
    "                continue\n",
    "            dst = partial_path['dst']\n",
    "            dst_name = vertex_info_df[vertex_info_df['id'] == dst]['stop_name'].values[0].encode('utf-8')\n",
    "            if partial_path['trip_id'] != 'walk' or partial_path['trip_id'] != 'sameStationTransfer':\n",
    "                next_dep = partial_path['dst_arr']\n",
    "                src_dep = partial_path['src_dep'].strftime(\"%H:%M:%S\")\n",
    "                dst_arr = partial_path['dst_arr'].strftime(\"%H:%M:%S\")\n",
    "            else: # if walk or same station transfer are in the later part of the path, need to be correct\n",
    "                time_cost = partial_path['dst_arr'] - partial_path['src_dep']\n",
    "                src_dep = next_dep.strftime(\"%H:%M:%S\")\n",
    "                dst_arr = next_dep + time_cost\n",
    "                next_dep = dst_arr\n",
    "                dst_arr = dst_arr.strftime(\"%H:%M:%S\")\n",
    "            trip_id = partial_path['trip_id']\n",
    "            print(\"[{}] From {}(id: {}) to {}(id: {}): {} ~ {}\".format(trip_id,src_name,src,dst_name,dst, src_dep,dst_arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# @TAs The next blocks is for you to run your querys\n",
    "\n",
    "Parameters:\n",
    "- dep_stop: stop id of the departure stop\n",
    "- arr_stop: stop id of the arrival stop\n",
    "- arr_time: expected arrival time\n",
    "\n",
    "**Ignore the date in the output, it is artifact of a workaround**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['8503000', u'8503000:0:14', u'8503006:0:6', u'8580449', '8591049']\n",
      "['8503000', u'8503000:0:14', u'8503006:0:6', u'8591314', '8591049']\n",
      "['8503000', u'8503000:0:14', u'8503006:0:6', u'8591382', '8591049']"
     ]
    }
   ],
   "source": [
    "### NOTE: heavy step, don't rerun this cell unless you changed your parameter\n",
    "\n",
    "# Change your query parameters here\n",
    "dep_stop = '8503000'\n",
    "arr_stop = '8591049'\n",
    "arr_time = '12:30:00'\n",
    "\n",
    "build_path_df = get_routes(all_edges_info_df, dep_stop, arr_stop, arr_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Route:\n",
      "[32.TA.80-159-Y-j19-1.8.H] From Zürich HB(id: 8503000:0:5) to Zürich Oerlikon(id: 8503006:0:6): 12:05:00 ~ 12:11:00\n",
      "[walk] From Zürich Oerlikon(id: 8503006:0:6) to Zürich Oerlikon, Bahnhof(id: 8580449): 12:13:38 ~ 12:15:00\n",
      "[1914.TA.26-11-A-j19-1.27.R] From Zürich Oerlikon, Bahnhof(id: 8580449) to Zürich, Auzelg(id: 8591049): 12:15:00 ~ 12:24:00\n",
      "Route:\n",
      "[32.TA.80-159-Y-j19-1.8.H] From Zürich HB(id: 8503000:0:5) to Zürich Oerlikon(id: 8503006:0:6): 12:05:00 ~ 12:11:00\n",
      "[walk] From Zürich Oerlikon(id: 8503006:0:6) to Zürich, Sternen Oerlikon(id: 8591382): 12:11:50 ~ 12:17:00\n",
      "[1914.TA.26-11-A-j19-1.27.R] From Zürich, Sternen Oerlikon(id: 8591382) to Zürich, Auzelg(id: 8591049): 12:17:00 ~ 12:24:00\n",
      "Route:\n",
      "[248.TA.26-6-A-j19-1.45.H] From Zürich HB(id: 8503000:0:41/42) to Zürich Oerlikon(id: 8503006:0:8): 12:01:00 ~ 12:08:00\n",
      "[walk] From Zürich Oerlikon(id: 8503006:0:8) to Zürich Oerlikon, Bahnhof(id: 8580449): 12:13:57 ~ 12:15:00\n",
      "[1914.TA.26-11-A-j19-1.27.R] From Zürich Oerlikon, Bahnhof(id: 8580449) to Zürich, Auzelg(id: 8591049): 12:15:00 ~ 12:24:00\n",
      "Route:\n",
      "[248.TA.26-6-A-j19-1.45.H] From Zürich HB(id: 8503000:0:41/42) to Zürich Oerlikon(id: 8503006:0:8): 12:01:00 ~ 12:08:00\n",
      "[walk] From Zürich Oerlikon(id: 8503006:0:8) to Zürich, Sternen Oerlikon(id: 8591382): 12:12:21 ~ 12:17:00\n",
      "[1914.TA.26-11-A-j19-1.27.R] From Zürich, Sternen Oerlikon(id: 8591382) to Zürich, Auzelg(id: 8591049): 12:17:00 ~ 12:24:00\n",
      "Route:\n",
      "[walk] From Zürich HB(id: 8503000:0:11) to Zürich, Stampfenbachplatz(id: 8591379): 11:58:56 ~ 12:03:00\n",
      "[1914.TA.26-11-A-j19-1.27.R] From Zürich, Stampfenbachplatz(id: 8591379) to Zürich, Bad Allenmoos(id: 8591053): 12:03:00 ~ 12:13:00\n",
      "[1914.TA.26-11-A-j19-1.27.R] From Zürich, Bad Allenmoos(id: 8591053) to Zürich, Auzelg(id: 8591049): 12:13:00 ~ 12:24:00\n",
      "Route:\n",
      "[walk] From Zürich HB(id: 8503000:0:11) to Zürich, Stampfenbachplatz(id: 8591379): 11:58:56 ~ 12:03:00\n",
      "[1914.TA.26-11-A-j19-1.27.R] From Zürich, Stampfenbachplatz(id: 8591379) to Zürich Oerlikon, Bahnhof(id: 8580449): 12:03:00 ~ 12:15:00\n",
      "[1914.TA.26-11-A-j19-1.27.R] From Zürich Oerlikon, Bahnhof(id: 8580449) to Zürich, Auzelg(id: 8591049): 12:15:00 ~ 12:24:00\n",
      "Route:\n",
      "[walk] From Zürich HB(id: 8503000:0:11) to Zürich, Stampfenbachplatz(id: 8591379): 11:58:56 ~ 12:03:00\n",
      "[1914.TA.26-11-A-j19-1.27.R] From Zürich, Stampfenbachplatz(id: 8591379) to Zürich, Messe/Hallenstadion(id: 8591273): 12:03:00 ~ 12:18:00\n",
      "[1914.TA.26-11-A-j19-1.27.R] From Zürich, Messe/Hallenstadion(id: 8591273) to Zürich, Auzelg(id: 8591049): 12:18:00 ~ 12:24:00\n",
      "Route:\n",
      "[walk] From Zürich HB(id: 8503000:0:11) to Zürich, Stampfenbachplatz(id: 8591379): 11:58:56 ~ 12:03:00\n",
      "[1914.TA.26-11-A-j19-1.27.R] From Zürich, Stampfenbachplatz(id: 8591379) to Zürich, Kronenstrasse(id: 8591237): 12:03:00 ~ 12:06:00\n",
      "[1914.TA.26-11-A-j19-1.27.R] From Zürich, Kronenstrasse(id: 8591237) to Zürich, Auzelg(id: 8591049): 12:06:00 ~ 12:24:00\n",
      "Route:\n",
      "[walk] From Zürich HB(id: 8503000:0:11) to Zürich, Stampfenbachplatz(id: 8591379): 11:58:56 ~ 12:03:00\n",
      "[1914.TA.26-11-A-j19-1.27.R] From Zürich, Stampfenbachplatz(id: 8591379) to Zürich, Leutschenbach(id: 8591256): 12:03:00 ~ 12:19:00\n",
      "[1914.TA.26-11-A-j19-1.27.R] From Zürich, Leutschenbach(id: 8591256) to Zürich, Auzelg(id: 8591049): 12:19:00 ~ 12:24:00\n",
      "Route:\n",
      "[walk] From Zürich HB(id: 8503000:0:11) to Zürich, Stampfenbachplatz(id: 8591379): 11:58:56 ~ 12:03:00\n",
      "[1914.TA.26-11-A-j19-1.27.R] From Zürich, Stampfenbachplatz(id: 8591379) to Zürich, Oerlikerhus(id: 8591294): 12:03:00 ~ 12:20:00\n",
      "[1914.TA.26-11-A-j19-1.27.R] From Zürich, Oerlikerhus(id: 8591294) to Zürich, Auzelg(id: 8591049): 12:20:00 ~ 12:24:00"
     ]
    }
   ],
   "source": [
    "### Show top N routes\n",
    "n = 10\n",
    "print_topN_routes(n, build_path_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result interpretation\n",
    "\n",
    "#### 1. For the query (dep_stop = '8503000', arr_stop = '8591049', arr_time = '12:30:00'), this is the result we obtained:\n",
    "\n",
    "Route:\n",
    "\n",
    "[32.TA.80-159-Y-j19-1.8.H] From Zürich HB(id: 8503000:0:5) to Zürich Oerlikon(id: 8503006:0:6): 12:05:00 ~ 12:11:00\n",
    "\n",
    "[walk] From Zürich Oerlikon(id: 8503006:0:6) to Zürich Oerlikon, Bahnhof(id: 8580449): 12:13:38 ~ 12:15:00\n",
    "\n",
    "[1914.TA.26-11-A-j19-1.27.R] From Zürich Oerlikon, Bahnhof(id: 8580449) to Zürich, Auzelg(id: 8591049): 12:15:00 ~ 12:24:00\n",
    "\n",
    "Route:\n",
    "\n",
    "[32.TA.80-159-Y-j19-1.8.H] From Zürich HB(id: 8503000:0:5) to Zürich Oerlikon(id: 8503006:0:6): 12:05:00 ~ 12:11:00\n",
    "\n",
    "[walk] From Zürich Oerlikon(id: 8503006:0:6) to Zürich, Sternen Oerlikon(id: 8591382): 12:11:50 ~ 12:17:00\n",
    "\n",
    "[1914.TA.26-11-A-j19-1.27.R] From Zürich, Sternen Oerlikon(id: 8591382) to Zürich, Auzelg(id: 8591049): 12:17:00 ~ 12:24:00\n",
    "\n",
    "Route:\n",
    "\n",
    "[248.TA.26-6-A-j19-1.45.H] From Zürich HB(id: 8503000:0:41/42) to Zürich Oerlikon(id: 8503006:0:8): 12:01:00 ~ 12:08:00\n",
    "\n",
    "[walk] From Zürich Oerlikon(id: 8503006:0:8) to Zürich Oerlikon, Bahnhof(id: 8580449): 12:13:57 ~ 12:15:00\n",
    "\n",
    "[1914.TA.26-11-A-j19-1.27.R] From Zürich Oerlikon, Bahnhof(id: 8580449) to Zürich, Auzelg(id: 8591049): 12:15:00 ~ 12:24:00\n",
    "\n",
    "Route:\n",
    "\n",
    "[248.TA.26-6-A-j19-1.45.H] From Zürich HB(id: 8503000:0:41/42) to Zürich Oerlikon(id: 8503006:0:8): 12:01:00 ~ 12:08:00\n",
    "\n",
    "[walk] From Zürich Oerlikon(id: 8503006:0:8) to Zürich, Sternen Oerlikon(id: 8591382): 12:12:21 ~ 12:17:00\n",
    "\n",
    "[1914.TA.26-11-A-j19-1.27.R] From Zürich, Sternen Oerlikon(id: 8591382) to Zürich, Auzelg(id: 8591049): 12:17:00 ~ 12:24:00\n",
    "\n",
    "\n",
    "#### 2. We captured the second-best route (departure at 12:05:00) and missed the best one:\n",
    "\n",
    "Route:\n",
    "\n",
    "[20.TA.26-9-A-j19-1.2.H] From Zürich HB(id: 8503000:0:41/42) to Glattbrugg(id: 8503310:0:3): 12:07:00 ~ 12:17:00\n",
    "\n",
    "[walk] From Glattbrugg(id: 8503310:0:3) to Glattbrugg, Bahnhof(id: 8590620): 12:21:56 ~ 12:23:00\n",
    "\n",
    "[168.TA.26-12-A-j19-1.2.H] From Glattbrugg, Bahnhof(id: 8590620) to Zürich, Auzelg(id: 8591049): 12:23:00 ~ 12:29:00\n",
    "\n",
    "After investigation in the dataset, we found that some entries in timetable do not have data in sbb dataset (They could be pruned from sbb during the preprocessing).\n",
    "And this is the reason we didn't find the best route.\n",
    "For the route planning algorithm, we only consider routes that have historical delay data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Part V] Evaluate the route uncertainty based on historical delay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea\n",
    "\n",
    "Here we model the certainty of a route using the cdf of the historical delay distribution at each transfer station.\n",
    "\n",
    "The certainty is calculated as the product of the probability of catching the change at each transfer station.\n",
    "\n",
    "The probability of catching the change at each transfer station is looked up directly from the the cdf of the historical delay distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "import math\n",
    "\n",
    "def time_diff(time_early,time_late):\n",
    "    #input should be datetime.datetime\n",
    "    diff=(time_early-time_late).total_seconds()\n",
    "    return diff\n",
    "\n",
    "def calc_delay_cdf(build_path_df,historical_delay):\n",
    "    success_rate=[]\n",
    "    build_path_df=build_path_df.reset_index(drop=True)\n",
    "    # workaround numpy limitation\n",
    "    date = '2000-01-01T'\n",
    "    arr_time_w_date = date + arr_time \n",
    "    for path_n in range(len(build_path_df)):\n",
    "        #we will calculate the proba of successfully catching transport inversely\n",
    "        src_dep=(pd.to_datetime(pd.Timestamp(arr_time_w_date)))\n",
    "        trip_len=len(build_path_df['paths_info'][path_n])\n",
    "        p_catch_accum=1\n",
    "        for i in list(range(trip_len))[::-1]:\n",
    "            dst=build_path_df['paths_info'][path_n][i]['dst']\n",
    "            trip_id=build_path_df['paths_info'][path_n][i]['trip_id']\n",
    "            if trip_id == \"sameStationTransfer\" or trip_id == \"walk\":\n",
    "                p_catch=1\n",
    "                src_dep=build_path_df['paths_info'][path_n][i]['src_dep']\n",
    "            else:\n",
    "                delay_for_trip = historical_delay[historical_delay['trip_id'] == trip_id].sort_values('src_dep')\n",
    "                dst_arr=build_path_df['paths_info'][path_n][i]['dst_arr']\n",
    "                delays=delay_for_trip[delay_for_trip['dst'] ==dst]['delays'].values[0]\n",
    "                tolerance_time=time_diff(src_dep,dst_arr)\n",
    "                src_dep=build_path_df['paths_info'][path_n][i]['src_dep']\n",
    "                delays = np.array(delays)\n",
    "                # number of elements in historical delays samller than tolerance time\n",
    "                if len(delays) == 0:\n",
    "                    p_catch = 1\n",
    "                else:\n",
    "                    p_catch=np.sum(delays<tolerance_time)/float(len(delays))\n",
    "            p_catch_accum*=p_catch\n",
    "        success_rate.append(p_catch_accum)\n",
    "    build_path_df['success_rate']=success_rate\n",
    "    return build_path_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print top N routes with given certainty threshold\n",
    "\n",
    "def print_topN_routes_w_certainty(n, certainty, build_path_df, all_edges_info_w_delay_df):\n",
    "    # Get historical delay data\n",
    "    historical_delay = all_edges_info_w_delay_df[['trip_id','src_dep','src','dst','dst_arr','time_cost', 'delays']]\n",
    "    temp = build_path_df.sort_values(['src_dep','time_cost'],ascending=[False,True])\n",
    "    firstN_w_certainty = calc_delay_cdf(temp, historical_delay)\n",
    "    firstN_w_certainty = firstN_w_certainty[firstN_w_certainty['success_rate'] > certainty].iloc[:n]\n",
    "\n",
    "    # Print top N routes with given certainty threshold \n",
    "    for path, probability in zip(firstN_w_certainty['paths_info'].values, firstN_w_certainty['success_rate'].values):\n",
    "        print(\"Route:\")\n",
    "        print(\"Probablity: {}\".format(probability))\n",
    "        # for walk to correct time\n",
    "        next_dep = path[0]['src_dep']\n",
    "        for partial_path in path:\n",
    "            src = partial_path['src']\n",
    "            try:\n",
    "                src_name = vertex_info_df[vertex_info_df['id'] == src]['stop_name'].values[0].encode('utf-8')\n",
    "            except:\n",
    "                continue\n",
    "            dst = partial_path['dst']\n",
    "            dst_name = vertex_info_df[vertex_info_df['id'] == dst]['stop_name'].values[0].encode('utf-8')\n",
    "            if partial_path['trip_id'] != 'walk' or partial_path['trip_id'] != 'sameStationTransfer':\n",
    "                next_dep = partial_path['dst_arr']\n",
    "                src_dep = partial_path['src_dep'].strftime(\"%H:%M:%S\")\n",
    "                dst_arr = partial_path['dst_arr'].strftime(\"%H:%M:%S\")\n",
    "            else: # if walk or same station transfer are in the later part of the path, need to be correct\n",
    "                time_cost = partial_path['dst_arr'] - partial_path['src_dep']\n",
    "                src_dep = next_dep.strftime(\"%H:%M:%S\")\n",
    "                dst_arr = next_dep + time_cost\n",
    "                next_dep = dst_arr\n",
    "                dst_arr = dst_arr.strftime(\"%H:%M:%S\")\n",
    "            trip_id = partial_path['trip_id']\n",
    "            print(\"[{}] From {}(id: {}) to {}(id: {}): {} ~ {}\".format(trip_id,src_name,src,dst_name,dst, src_dep,dst_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Route:\n",
      "Probablity: 0.970904584882\n",
      "[32.TA.80-159-Y-j19-1.8.H] From Zürich HB(id: 8503000:0:5) to Zürich Oerlikon(id: 8503006:0:6): 12:05:00 ~ 12:11:00\n",
      "[walk] From Zürich Oerlikon(id: 8503006:0:6) to Zürich Oerlikon, Bahnhof(id: 8580449): 12:13:38 ~ 12:15:00\n",
      "[1914.TA.26-11-A-j19-1.27.R] From Zürich Oerlikon, Bahnhof(id: 8580449) to Zürich, Auzelg(id: 8591049): 12:15:00 ~ 12:24:00\n",
      "Route:\n",
      "Probablity: 0.982893458175\n",
      "[248.TA.26-6-A-j19-1.45.H] From Zürich HB(id: 8503000:0:41/42) to Zürich Oerlikon(id: 8503006:0:8): 12:01:00 ~ 12:08:00\n",
      "[walk] From Zürich Oerlikon(id: 8503006:0:8) to Zürich Oerlikon, Bahnhof(id: 8580449): 12:13:57 ~ 12:15:00\n",
      "[1914.TA.26-11-A-j19-1.27.R] From Zürich Oerlikon, Bahnhof(id: 8580449) to Zürich, Auzelg(id: 8591049): 12:15:00 ~ 12:24:00\n",
      "Route:\n",
      "Probablity: 0.974702679356\n",
      "[248.TA.26-6-A-j19-1.45.H] From Zürich HB(id: 8503000:0:41/42) to Zürich Oerlikon(id: 8503006:0:8): 12:01:00 ~ 12:08:00\n",
      "[walk] From Zürich Oerlikon(id: 8503006:0:8) to Zürich, Sternen Oerlikon(id: 8591382): 12:12:21 ~ 12:17:00\n",
      "[1914.TA.26-11-A-j19-1.27.R] From Zürich, Sternen Oerlikon(id: 8591382) to Zürich, Auzelg(id: 8591049): 12:17:00 ~ 12:24:00\n",
      "Route:\n",
      "Probablity: 0.986988847584\n",
      "[walk] From Zürich HB(id: 8503000:0:11) to Zürich, Stampfenbachplatz(id: 8591379): 11:58:56 ~ 12:03:00\n",
      "[1914.TA.26-11-A-j19-1.27.R] From Zürich, Stampfenbachplatz(id: 8591379) to Zürich, Auzelg(id: 8591049): 12:03:00 ~ 12:24:00\n",
      "Route:\n",
      "Probablity: 0.986988847584\n",
      "[walk] From Zürich HB(id: 8503000:0:10) to Zürich, Stampfenbachplatz(id: 8591379): 11:58:54 ~ 12:03:00\n",
      "[1914.TA.26-11-A-j19-1.27.R] From Zürich, Stampfenbachplatz(id: 8591379) to Zürich, Auzelg(id: 8591049): 12:03:00 ~ 12:24:00\n",
      "Route:\n",
      "Probablity: 0.986988847584\n",
      "[walk] From Zürich HB(id: 8503000:0:3) to Zürich, Stampfenbachplatz(id: 8591379): 11:58:52 ~ 12:03:00\n",
      "[1914.TA.26-11-A-j19-1.27.R] From Zürich, Stampfenbachplatz(id: 8591379) to Zürich, Auzelg(id: 8591049): 12:03:00 ~ 12:24:00\n",
      "Route:\n",
      "Probablity: 0.986988847584\n",
      "[walk] From Zürich HB(id: 8503000:0:4) to Zürich, Stampfenbachplatz(id: 8591379): 11:58:49 ~ 12:03:00\n",
      "[1914.TA.26-11-A-j19-1.27.R] From Zürich, Stampfenbachplatz(id: 8591379) to Zürich, Auzelg(id: 8591049): 12:03:00 ~ 12:24:00\n",
      "Route:\n",
      "Probablity: 0.986988847584\n",
      "[walk] From Zürich HB(id: 8503000:0:17) to Zürich, Stampfenbachplatz(id: 8591379): 11:58:46 ~ 12:03:00\n",
      "[1914.TA.26-11-A-j19-1.27.R] From Zürich, Stampfenbachplatz(id: 8591379) to Zürich, Auzelg(id: 8591049): 12:03:00 ~ 12:24:00\n",
      "Route:\n",
      "Probablity: 0.986988847584\n",
      "[walk] From Zürich HB(id: 8503000:0:32) to Zürich, Stampfenbachplatz(id: 8591379): 11:58:43 ~ 12:03:00\n",
      "[1914.TA.26-11-A-j19-1.27.R] From Zürich, Stampfenbachplatz(id: 8591379) to Zürich, Auzelg(id: 8591049): 12:03:00 ~ 12:24:00\n",
      "Route:\n",
      "Probablity: 0.986988847584\n",
      "[walk] From Zürich HB(id: 8503000:0:31) to Zürich, Stampfenbachplatz(id: 8591379): 11:58:40 ~ 12:03:00\n",
      "[1914.TA.26-11-A-j19-1.27.R] From Zürich, Stampfenbachplatz(id: 8591379) to Zürich, Auzelg(id: 8591049): 12:03:00 ~ 12:24:00"
     ]
    }
   ],
   "source": [
    "# Print top N routes with given certainty threshold\n",
    "\n",
    "# will take 1 or 2 minutes\n",
    "# Change the following parameters for your experiment\n",
    "n = 10\n",
    "certainty = 0.8\n",
    "print_topN_routes_w_certainty(n, certainty, build_path_df, all_edges_info_w_delay_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pros:\n",
    "1. This algorithm can find paths within small number of n of the n-depth DFS (nx.all_simple_path) because we connect all the path in one trip so that the algo can know all the possible destination if we get on the trip and thus find out the path. And the number of cutoff here is actually the number of transfer. Furthermore, based on our assumption 3, the number of transfer time will not exceed 4. So it is highly possible to find a path given small n.\n",
    "2. Use greedy deduce previous path is easy to find the latest departure time. We always take the trip with latest departure time in the partial path. In this case, we can just check if the latest departure one in the previous partial path arrive before this latest departure time. If yes, then we can continue to move forwards the deduction, otherwise, it means this path fail and it is not possible during this period.\n",
    "\n",
    "## Cons:\n",
    "1. This algorithm need to consider all the possible path from the n-depth DFS. And the number of paths are usually very large, which cost much time to rebuild all the path. But this can be improved by building the all paths once and pickle it for future use. Thus this is not a huge concern.\n",
    "2. Furthermore, this algorithm can just get the result after rebuilding all the possible paths (using sorting).\n",
    "3. There is still possibility to find a real latest departure path because we just consider transfer within 4 times, although we think this probability is very small.\n",
    "4. Here we model the certainty of a route using the cdf of the delay distribution. A better way would be to model some common distributions, e.g., lognorm, such that the model generalizes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Possible Improvement:\n",
    "1. The algorithm have very large space to improve as what we designed here is basically brute force. For this problem, it can actually be constructed in an constraint shortest path problem. We had tried for few days but still cannot figure out the way how to add constraint to the problem. Apart from this, randomization algorithm may also work.\n",
    "2. We model the certainty of a route using the CDF of the delay distribution. A better way would be to fit the data into some common distributions, e.g., lognorm, such that the model generalizes.\n",
    "3. In pratical aspect, travaler can start at any platform inside one station, such as Zurich HB. But for now we only support input a sinle platform(not Zurich HB as a whole). This remains to be imrpoved for better user experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
